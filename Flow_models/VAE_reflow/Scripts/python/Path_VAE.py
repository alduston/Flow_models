# -*- coding: utf-8 -*-
"""Path_VAE.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wfmesT7LM4pDuIJzatShrBXiku8I-XdF
"""

# =================== nd AVRC training + sampling (+ standard Rectified Flow) ===================
# Includes:
#   • PyTorch-native OT-Flow-style nd samplers
#   • AVRC (x1-only) trainer in R^D
#   • Standard Rectified Flow (RF) baseline trainer in R^D
#   • nd metrics (MMD, sliced-W2), utilities, and samplers
#
# Changelog (diagnostics):
#   • sliced_w2 now supports max_n subsampling for faster diagnostics
#   • (unchanged otherwise; logging/timing added in the viz/main cell)

import math, time, os
from dataclasses import dataclass
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F

# -------------------------------- device & dtype --------------------------------------
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
TDTYPE = torch.float32


def _square_limits(xlim, ylim, c_exp = 1.15):
    """
    Make xlim, ylim square in data coordinates.
    We keep the centers the same, just expand the smaller span.
    """
    x0, x1 = float(xlim[0]), float(xlim[1])
    y0, y1 = float(ylim[0]), float(ylim[1])
    xc = 0.5 * (x0 + x1)
    yc = 0.5 * (y0 + y1)
    w = x1 - x0
    h = y1 - y0
    side = c_exp * max(w, h)
    xlim_sq = (xc - 0.5*side, xc + 0.5*side)
    ylim_sq = (yc - 0.5*side, yc + 0.5*side)
    return list(xlim_sq), list(ylim_sq)

# --------------------------------- random utils ---------------------------------------
def seed_everything(seed: int | None):
    if seed is None: return
    torch.manual_seed(seed); np.random.seed(seed)

# -------------------------------- time embedding --------------------------------------
def t_embed(t: torch.Tensor):
    """Simple 4-dim time features; t in [0,1], returns (B,4)."""
    return torch.cat([t, torch.sin(2*math.pi*t), torch.cos(2*math.pi*t), t*t], dim=1)

# ---------------------------------- MLP blocks ----------------------------------------
class MLP(nn.Module):
    def __init__(self, din, dout, hidden=128, depth=4, act=nn.SiLU):
        super().__init__()
        layers = []
        d = din
        for _ in range(depth-1):
            layers += [nn.Linear(d, hidden), act()]
            d = hidden
        layers += [nn.Linear(d, dout)]
        self.net = nn.Sequential(*layers)
        for m in self.modules():
            if isinstance(m, nn.Linear):
                nn.init.xavier_uniform_(m.weight); nn.init.zeros_(m.bias)
    def forward(self, x): return self.net(x)

# ------------------------------ Enhanced MLP (RF) ------------------------------------
class SinusoidalTimeEmbedding(nn.Module):
    """Sinusoidal time embedding: maps t∈[0,1] (B,1) to (B,dim)."""
    def __init__(self, dim: int):
        super().__init__()
        self.dim = int(dim)
        # frequencies: exponential range as in transformer pos-emb
        half = self.dim // 2
        exp_range = torch.arange(half).float()
        # register as buffer to keep on same device/dtype
        self.register_buffer("freqs", torch.exp(-math.log(10000.0) * exp_range / max(1, half)), persistent=False)

    def forward(self, t: torch.Tensor) -> torch.Tensor:
        # t: (B,1) in [0,1]
        angles = t * self.freqs.view(1, -1)
        emb_sin = torch.sin(angles)
        emb_cos = torch.cos(angles)
        emb = torch.cat([emb_sin, emb_cos], dim=1)
        if emb.size(1) < self.dim:
            # pad to exact dim if odd
            emb = F.pad(emb, (0, self.dim - emb.size(1)))
        return emb

class EnhancedMLP(nn.Module):
    """
    Enhanced MLP for rectified flow velocity fields with:
    - sinusoidal time embedding
    - FiLM-style modulation per block (scale/shift from time embedding)
    - residual skip connections
    - zero-init final layer for stable training
    """
    def __init__(
        self,
        input_dim: int,
        output_dim: int,
        hidden: int = 256,
        depth: int = 6,
        time_embed_dim: int = 128,
        act: type[nn.Module] = nn.SiLU,
        dropout: float = 0.0,
        final_zero_init: bool = True,
        use_layer_norm: bool = True,
    ):
        super().__init__()
        self.input_dim = int(input_dim)
        self.output_dim = int(output_dim)
        self.hidden = int(hidden)
        self.depth = int(max(1, depth))
        self.act = act()
        self.dropout = nn.Dropout(dropout) if dropout and dropout > 0 else nn.Identity()
        self.use_layer_norm = bool(use_layer_norm)

        # time embedding -> hidden
        self.time_emb = SinusoidalTimeEmbedding(time_embed_dim)
        self.time_mlp = nn.Sequential(
            nn.Linear(time_embed_dim, hidden),
            nn.SiLU(),
            nn.Linear(hidden, hidden),
        )
        # per-block FiLM (scale, shift)
        self.film = nn.ModuleList([nn.Linear(hidden, 2*hidden) for _ in range(self.depth)])

        # input projection
        self.input_proj = nn.Linear(self.input_dim, hidden)
        # blocks
        self.blocks = nn.ModuleList([nn.Linear(hidden, hidden) for _ in range(self.depth)])
        self.norms  = nn.ModuleList([nn.LayerNorm(hidden) if self.use_layer_norm else nn.Identity() for _ in range(self.depth)])

        # output head
        self.output_proj = nn.Linear(hidden, self.output_dim)

        # init
        for m in self.modules():
            if isinstance(m, nn.Linear):
                nn.init.xavier_uniform_(m.weight)
                nn.init.zeros_(m.bias)
        if final_zero_init:
            nn.init.zeros_(self.output_proj.weight)
            nn.init.zeros_(self.output_proj.bias)

    def forward(self, x: torch.Tensor, t: torch.Tensor) -> torch.Tensor:
        # x: (B, D), t: (B,1)
        h = self.input_proj(x)
        # shared time embedding
        te = self.time_mlp(self.time_emb(t))
        for i in range(self.depth):
            res = h
            h = self.blocks[i](h)
            h = self.norms[i](h)
            # FiLM modulation
            s, b = self.film[i](te).chunk(2, dim=1)
            h = h * (1.0 + s) + b
            h = self.act(h)
            h = self.dropout(h)
            h = h + res
        return self.output_proj(h)

# ------------------------------ Encoders / heads (D-dim) ------------------------------
class GaussianHead(nn.Module):
    """
    Outputs [mu (D), logvar (D)] with last layer zeroed so initial mu=0, logvar=0.
    """
    def __init__(self, din: int, D: int, hidden=128, depth=4):
        super().__init__()
        self.D = D
        self.mlp = MLP(din, 2*D, hidden=hidden, depth=depth)
        # force constant zero init
        for m in reversed(list(self.mlp.modules())):
            if isinstance(m, nn.Linear):
                nn.init.zeros_(m.weight); nn.init.zeros_(m.bias); break

    def forward(self, x):
        h = self.mlp(x)
        mu, logvar = h[:, :self.D], h[:, self.D:]
        return mu, logvar

def reparam(mu, logvar):
    std = torch.exp(0.5*logvar)
    eps = torch.randn_like(std)
    return mu + std*eps

def kl_normal_diag(mu, logvar):
    """
    E_x [ KL( N(mu, diag(exp(logvar))) || N(0,I) ) ] averaged over batch.
    """
    elem = mu.pow(2) + logvar.exp() - logvar - 1.0
    return 0.5 * torch.mean(elem.sum(dim=1))

class EncoderX1Only(nn.Module):
    """z0 = E(x1) (destination-only encoder) in D dims."""
    def __init__(self, D=2, hidden=128, depth=4):
        super().__init__()
        self.D = D
        self.head = GaussianHead(D, D, hidden=hidden, depth=depth)
    def forward(self, x1): return self.head(x1)

# --------------------------- encoder output helpers ---------------------------
def unpack_encoder_output(enc_out):
    """
    Normalize encoder outputs to `(mu, logv, z1)` where **z1 is ALWAYS mu**.

    Rationale: path-VAE regime wants the endpoint to be the deterministic
    mean code μ(x). Even if an encoder happens to produce an extra endpoint,
    we ignore it and use μ.
    """
    if not isinstance(enc_out, (tuple, list)):
        raise TypeError("Encoder is expected to return a tuple")

    if len(enc_out) == 3:
        mu, logv, _ = enc_out      # discard old learned endpoint
    elif len(enc_out) == 2:
        mu, logv = enc_out
    else:
        raise ValueError(f"Unexpected encoder output length: {len(enc_out)}")

    z1 = mu                        # <- key line
    return mu, logv, z1


# --------------------- Enhanced Encoder (Pro) and components ---------------------
class RFF(nn.Module):
    def __init__(self, D, n_freq=0, freq_scale=1.0, trainable=False):
        super().__init__()
        self.n_freq = int(n_freq)
        if self.n_freq > 0:
            B = torch.randn(self.n_freq, D) * float(freq_scale)
            self.register_parameter("B", nn.Parameter(B, requires_grad=trainable))
        else:
            self.register_parameter("B", None)

    def forward(self, x):
        if self.n_freq <= 0:
            return x
        proj = x @ self.B.T
        s, c = torch.sin(proj), torch.cos(proj)
        return torch.cat([x, s, c], dim=1)

class GeGLU(nn.Module):
    def __init__(self, d_in, d_out):
        super().__init__()
        self.W = nn.Linear(d_in, 2*d_out)
    def forward(self, x):
        a, g = self.W(x).chunk(2, dim=-1)
        return a * F.gelu(g)

class ResBlock(nn.Module):
    def __init__(self, d, hidden, dropout=0.0, act=nn.SiLU, use_geglu=True):
        super().__init__()
        self.norm = nn.LayerNorm(d)
        self.ff1  = (GeGLU(d, hidden) if use_geglu else nn.Sequential(
                        nn.Linear(d, hidden), act()))
        self.drop = nn.Dropout(dropout)
        self.ff2  = nn.Linear(hidden, d)
        nn.init.zeros_(self.ff2.bias)
        nn.init.normal_(self.ff2.weight, mean=0.0, std=1e-3)

    def forward(self, x):
        h = self.norm(x)
        h = self.ff1(h)
        h = self.drop(h)
        h = self.ff2(h)
        return x + h

class OrthoMix(nn.Module):
    def __init__(self, D, n_householder=4):
        super().__init__()
        self.v = nn.Parameter(torch.randn(n_householder, D))

    def forward(self, x):
        Qx = x
        for v in self.v:
            v = F.normalize(v, dim=0, eps=1e-12)
            Qx = Qx - 2.0 * (Qx @ v.unsqueeze(1)) * v.unsqueeze(0)
        return Qx

class GaussianHeadPro(nn.Module):
    def __init__(self, D, width=512, depth=8, dropout=0.0, ff_freqs=16,
                 ff_scale=1.0, use_geglu=True, residual_mu=True,
                 ortho_mix=False, n_householder=4,
                 logvar_min=-10.0, logvar_max=+6.0,
                 produce_endpoint: bool = False):
        super().__init__()
        self.D = int(D)
        self.residual_mu = bool(residual_mu)
        self.logvar_min = float(logvar_min)
        self.logvar_max = float(logvar_max)
        self.produce_endpoint = bool(produce_endpoint)

        self.rff = RFF(D, n_freq=ff_freqs, freq_scale=ff_scale, trainable=False)
        feat_dim = D + 2*ff_freqs

        self.mixer = OrthoMix(D, n_householder=n_householder) if ortho_mix else None

        blocks = [nn.Linear(feat_dim, width), nn.SiLU()]
        for _ in range(depth):
            blocks.append(ResBlock(width, width, dropout=dropout, use_geglu=use_geglu))
        self.trunk = nn.Sequential(*blocks)

        self.mu_head     = nn.Linear(width, D)
        self.logvar_head = nn.Linear(width, D)
        if self.produce_endpoint:
            self.z1_head = nn.Linear(width, D)
        for m in (self.mu_head, self.logvar_head):
            nn.init.zeros_(m.weight); nn.init.zeros_(m.bias)
        if self.produce_endpoint:
            nn.init.zeros_(self.z1_head.weight)
            nn.init.zeros_(self.z1_head.bias)

        self.alpha = nn.Parameter(torch.tensor(0.0)) if self.residual_mu else None

    def forward(self, x):
        xin = self.mixer(x) if (self.mixer is not None) else x
        h   = self.rff(xin)
        h   = self.trunk(h)

        dmu = self.mu_head(h)
        if self.residual_mu and self.alpha is not None:
            mu = x + self.alpha.tanh() * dmu
        else:
            mu = dmu

        logv = self.logvar_head(h)
        logv = torch.clamp(logv, self.logvar_min, self.logvar_max)
        if self.produce_endpoint:
            z1 = self.z1_head(h)
            return mu, logv, z1
        return mu, logv

class EncoderX1OnlyPro(nn.Module):
    def __init__(self, D=2, width=512, depth=8, dropout=0.05,
                 ff_freqs=16, ff_scale=1.0, use_geglu=True,
                 residual_mu=False,
                 ortho_mix=False, n_householder=4,
                 logvar_min=-10.0, logvar_max=+6.0,
                 produce_endpoint: bool = False):

        super().__init__()
        self.D = int(D)
        self.produce_endpoint = bool(produce_endpoint)
        self.head = GaussianHeadPro(
            D, width=width, depth=depth, dropout=dropout,
            ff_freqs=ff_freqs, ff_scale=ff_scale, use_geglu=use_geglu,
            residual_mu=residual_mu, ortho_mix=ortho_mix, n_householder=n_householder,
            logvar_min=logvar_min, logvar_max=logvar_max,
            produce_endpoint=self.produce_endpoint
        )

    def forward(self, x1):
        out = self.head(x1)
        if self.produce_endpoint:
            return out  # (mu, logv, z1)
        return out

class Velocity(nn.Module):
    """v(x,t) -> R^D (mean-field velocity in data space)."""
    def __init__(self, D=2, hidden=128, depth=4):
        super().__init__()
        self.D = D
        self.net = EnhancedMLP(input_dim=D, output_dim=D, hidden=hidden, depth=depth)
    def forward(self, x, t): return self.net(x, t)

# -------------------------------- Schedules / frames ----------------------------------
def lin_sched(a, b, step, total):
    s = min(max(step / max(total, 1), 0.0), 1.0)
    return a + (b - a) * s

def _make_log_stride_rounds(total_rounds: int,
                            first_dense: int = 20,
                            growth: float = 2.0,
                            stride0: int = 1,
                            max_stride: int | None = None) -> list[int]:
    frames: list[int] = []
    start = 1
    L = max(1, int(first_dense))
    stride = max(1, int(stride0))
    while start <= total_rounds:
        end = min(total_rounds, start + L - 1)
        use_stride = min(stride, max_stride) if (max_stride is not None) else stride
        frames.extend(range(start, end + 1, use_stride))
        start = end + 1
        L = max(1, int(round(L * growth)))
        stride = max(1, int(round(stride * growth)))
    return sorted(set(frames))


# ------------------------------ Projection helpers (NEW) ------------------------------
@torch.no_grad()
def _orthonormalize_cols(A: torch.Tensor) -> torch.Tensor:
    # A: (D, k); returns Q with orthonormal columns (thin Gram-Schmidt)
    Q = []
    for i in range(A.size(1)):
        v = A[:, i]
        for j in range(len(Q)):
            v = v - (Q[j].T @ v) * Q[j]
        v = v / (v.norm() + 1e-12)
        Q.append(v)
    return torch.stack(Q, dim=1)

@torch.no_grad()
def choose_projection_pairs(
    D: int,
    *,
    data_for_pca: torch.Tensor | None = None,   # (N, D) or None
    num_pairs: int = 3,
    mode: str = "pca",                           # {"pca","random"}
    seed: int | None = 1234
) -> list[torch.Tensor]:
    """
    Returns a list of P_i ∈ R^{D×2}. If mode='pca' and data is given,
    uses leading 2,4,6,... components as pairs. Otherwise random pairs.
    """
    pairs: list[torch.Tensor] = []
    if mode == "pca" and (data_for_pca is not None) and (data_for_pca.ndim == 2) and (data_for_pca.size(1) == D):
        X = data_for_pca - data_for_pca.mean(dim=0, keepdim=True)
        # torch.pca_lowrank is efficient and differentiable-free
        q = min(D, 2 * num_pairs)
        U, S, V = torch.pca_lowrank(X, q=q, center=False)  # V: (D, q)
        for i in range(num_pairs):
            a = 2*i
            b = 2*i + 1
            if b >= V.size(1): break
            P = V[:, a:b+1]                      # (D, 2)
            P = _orthonormalize_cols(P)          # be safe
            pairs.append(P.to(device=device, dtype=TDTYPE))
    else:
        if seed is not None:
            gen = torch.Generator(device=device)
            gen.manual_seed(int(seed))
        else:
            gen = None
        for _ in range(num_pairs):
            R = torch.randn(D, 2, device=device, dtype=TDTYPE, generator=gen)
            P = _orthonormalize_cols(R)
            pairs.append(P)
    return pairs

@torch.no_grad()
def project_nd(X: torch.Tensor, P: torch.Tensor) -> torch.Tensor:
    """
    X: (N, D), P: (D, 2) with orthonormal columns.
    Returns (N, 2).
    """
    return X @ P


# ===================== EMBEDDING: globals & helpers =====================
EMBEDDING_MODE = "identity"   # {"identity","linear","sine_wiggle","rff","radial"}
EMBEDDING_DIM  = 2            # target ambient dimension K after embedding

# global cache: (mode, m, k_dim, device, dtype) -> params dict
_EMBED_CACHE: dict[tuple, dict[str, torch.Tensor | None]] = {}

def set_embedding(mode: str = "identity", dim: int = 2):
    """
    Set global embedding mode and ambient dimension K.
    Also clears the cached random params so that switching mode/dim regenerates them once.
    """
    global EMBEDDING_MODE, EMBEDDING_DIM, _EMBED_CACHE
    EMBEDDING_MODE = str(mode).lower().strip()
    EMBEDDING_DIM  = int(dim)
    _EMBED_CACHE.clear()   # important: avoid mixing params from old dims/modes


# ---------- linear-algebra helpers ----------
def _qr_tall(k: int, m: int, *, device, dtype):
    """
    Return Q in R^{k×m} with orthonormal columns (k >= m).
    """
    assert k >= m and k > 0 and m > 0
    G = torch.randn(k, m, device=device, dtype=dtype)
    Q, _ = torch.linalg.qr(G, mode='reduced')  # Q:(k,m)
    return Q

def _qr_wide(m: int, k: int, *, device, dtype):
    """
    Return A in R^{m×k} with orthonormal columns (k <= m).
    """
    assert m >= k and k > 0 and m > 0
    G = torch.randn(m, k, device=device, dtype=dtype)
    Q, _ = torch.linalg.qr(G, mode='reduced')  # Q:(m,k)
    return Q

def _orthonormal_complement(Q: torch.Tensor, k: int, s: int, *, device, dtype):
    """
    Given Q (k×m) with orthonormal cols, return Q_perp (k×s) with orthonormal cols and Q^T Q_perp = 0.
    """
    if s <= 0:
        return None
    m = Q.shape[1]
    assert Q.shape == (k, m)
    G = torch.randn(k, s, device=device, dtype=dtype)
    # project G to be orthogonal to span(Q)
    G = G - Q @ (Q.transpose(0,1) @ G)
    Qp, _ = torch.linalg.qr(G, mode='reduced')  # (k,s)
    return Qp[:, :s]


# ---------- cache helper ----------
def _get_cached(key: tuple, builder):
    """
    key: (mode, m, k_dim, device, dtype, ...)
    builder: () -> dict[str, Tensor]
    """
    if key not in _EMBED_CACHE:
        _EMBED_CACHE[key] = builder()
    return _EMBED_CACHE[key]


# ---------- linear embedding (deterministic) ----------
@torch.no_grad()
def _get_linear_params(m: int, k_dim: int, device, dtype):
    key = ("linear", m, k_dim, device, dtype)
    def _build():
        if k_dim > m:
            Q = _qr_tall(k_dim, m, device=device, dtype=dtype)  # (k,m)
            return {"Q": Q}
        else:
            return {}  # no params needed
    return _get_cached(key, _build)

@torch.no_grad()
def _embed_linear(X: torch.Tensor, k_dim: int) -> torch.Tensor:
    """
    Deterministic linear lift/reduce into R^{k_dim}. X: (n,m).
    """
    device, dtype = X.device, X.dtype
    n, m = X.shape
    if k_dim > m:
        params = _get_linear_params(m, k_dim, device, dtype)
        Q = params["Q"]                      # (k,m)
        return X @ Q.transpose(0, 1)         # (n,k)
    else:
        return X[:, :k_dim]


# ---------- sine-wiggle embedding (deterministic) ----------
@torch.no_grad()
def _get_sine_wiggle_params(m: int, k_dim: int, device, dtype,
                            amp: float = 0.25, freq: float = 1.0):
    """
    Build (once) and cache the random ingredients for sine-wiggle embedding.
    Ensures the target is stationary across calls.
    """
    key = ("sine_wiggle", m, k_dim, device, dtype, float(amp), float(freq))
    def _build():
        params: dict[str, torch.Tensor | None] = {}
        # case 1: lift 2 -> K (K > m)
        if k_dim > m:
            Q = _qr_tall(k_dim, m, device=device, dtype=dtype)  # (k,m)
            s = k_dim - m                                       # true complement size
            if s > 0:
                Q_perp = _orthonormal_complement(Q, k_dim, s, device=device, dtype=dtype)  # (k,s)
                R = torch.randn(s, m, device=device, dtype=dtype) * freq
                b = 2.0 * math.pi * torch.rand(s, device=device, dtype=dtype)
            else:
                Q_perp, R, b = None, None, None
            params.update(dict(
                Q=Q, Q_perp=Q_perp, R=R, b=b,
                amp=torch.tensor(amp, device=device, dtype=dtype),
            ))
        # case 2: same dim (K == m)  <-- your K=2 case
        elif k_dim == m:
            # keep linear part fixed (identity)
            Q = torch.eye(m, device=device, dtype=dtype)
            R = torch.randn(m, m, device=device, dtype=dtype) * freq
            b = 2.0 * math.pi * torch.rand(m, device=device, dtype=dtype)
            params.update(dict(
                Q=Q, Q_perp=None, R=R, b=b,
                amp=torch.tensor(amp, device=device, dtype=dtype),
            ))
        # case 3: reduce (K < m)
        else:
            A = _qr_wide(m, k_dim, device=device, dtype=dtype)  # (m,k)
            R = torch.randn(k_dim, m, device=device, dtype=dtype) * freq
            b = 2.0 * math.pi * torch.rand(k_dim, device=device, dtype=dtype)
            params.update(dict(
                A=A, R=R, b=b,
                amp=torch.tensor(amp, device=device, dtype=dtype),
            ))
        return params
    return _get_cached(key, _build)

@torch.no_grad()
def _embed_sine_wiggle(X: torch.Tensor, k_dim: int,
                       amp: float = 0.25, freq: float = 1.0) -> torch.Tensor:
    device, dtype = X.device, X.dtype
    n, m = X.shape
    params = _get_sine_wiggle_params(m, k_dim, device, dtype, amp=amp, freq=freq)

    # lift
    if k_dim > m:
        Q      = params["Q"]      # (k,m)
        Q_perp = params["Q_perp"] # (k,s) or None
        amp_t  = params["amp"]
        Zlin = X @ Q.transpose(0, 1)  # (n,k)
        if Q_perp is not None:
            R = params["R"]          # (s,m)
            b = params["b"]          # (s,)
            H = torch.sin(X @ R.transpose(0, 1) + b)  # (n,s)
            Zwig = H @ Q_perp.transpose(0, 1)         # (n,k)
            return Zlin + amp_t * Zwig
        else:
            return Zlin

    # same dim
    elif k_dim == m:
        Q     = params["Q"]   # (m,m)
        R     = params["R"]   # (m,m)
        b     = params["b"]   # (m,)
        amp_t = params["amp"]
        Zlin  = X @ Q.transpose(0, 1)             # == X
        H     = torch.sin(X @ R.transpose(0, 1) + b)  # (n,m)
        return Zlin + amp_t * H

    # reduce
    else:  # k_dim < m
        A     = params["A"]   # (m,k)
        R     = params["R"]   # (k,m)
        b     = params["b"]   # (k,)
        amp_t = params["amp"]
        Zlin  = X @ A                         # (n,k)
        H     = torch.sin(X @ R.transpose(0, 1) + b)  # (n,k)
        return Zlin + amp_t * H


# ---------- RFF embedding (deterministic) ----------
@torch.no_grad()
def _get_rff_params(m: int, k_dim: int, device, dtype, freq: float):
    key = ("rff", m, k_dim, device, dtype, float(freq))
    def _build():
        M = max(1, k_dim // 2)
        W = torch.randn(M, m, device=device, dtype=dtype) * freq  # (M,m)
        b = 2.0 * math.pi * torch.rand(M, device=device, dtype=dtype)
        # if we need linear pad later, we can draw once here
        extra = None
        if 2 * M < k_dim:
            extra = torch.randn(m, k_dim - 2 * M, device=device, dtype=dtype)
        return {"W": W, "b": b, "extra": extra, "M": M}
    return _get_cached(key, _build)

@torch.no_grad()
def _embed_rff(X: torch.Tensor, k_dim: int, freq: float = 1.0) -> torch.Tensor:
    device, dtype = X.device, X.dtype
    n, m = X.shape
    params = _get_rff_params(m, k_dim, device, dtype, freq)
    W, b, extra, M = params["W"], params["b"], params["extra"], params["M"]

    C = torch.cos(X @ W.transpose(0, 1) + b)  # (n,M)
    S = torch.sin(X @ W.transpose(0, 1) + b)  # (n,M)
    Z = torch.cat([C, S], dim=1)              # (n,2M)

    if Z.shape[1] < k_dim:
        # deterministic pad
        pad = X @ extra                        # (n, k_dim - 2M)
        Z = torch.cat([Z, pad], dim=1)
    else:
        Z = Z[:, :k_dim]
    return Z


# ---------- radial embedding (deterministic) ----------
@torch.no_grad()
def _get_radial_params(m: int, k_dim: int, device, dtype):
    key = ("radial", m, k_dim, device, dtype)
    def _build():
        base = m + 4  # X + r + r^2 + sin r + cos r
        n_extra = max(0, k_dim - base)
        extra_ws = None
        if n_extra > 0:
            extra_ws = torch.randn(m, n_extra, device=device, dtype=dtype)
        return {"extra_ws": extra_ws, "n_extra": n_extra}
    return _get_cached(key, _build)

@torch.no_grad()
def _embed_radial(X: torch.Tensor, k_dim: int) -> torch.Tensor:
    device, dtype = X.device, X.dtype
    n, m = X.shape
    r = torch.linalg.norm(X, dim=1, keepdim=True)  # (n,1)
    Z = torch.cat([X, r, r**2, torch.sin(r), torch.cos(r)], dim=1)  # (n, m+4)

    if Z.shape[1] >= k_dim:
        return Z[:, :k_dim]

    params = _get_radial_params(m, k_dim, device, dtype)
    extra_ws, n_extra = params["extra_ws"], params["n_extra"]
    if n_extra > 0:
        extra_feats = (X @ extra_ws) ** 2      # (n, n_extra)
        Z = torch.cat([Z, extra_feats], dim=1)
    return Z[:, :k_dim]


# ---------- public dispatch ----------
@torch.no_grad()
def embed_to_k(X2d: torch.Tensor, mode: str, k_dim: int) -> torch.Tensor:
    """
    Dispatch entry: X2d (n,2) --> Z (n,k_dim) according to mode.
    All modes are now stationary (random parts are cached).
    """
    mode = str(mode).lower().strip()
    if k_dim == 2 and mode in ("identity", "", None):
        return X2d

    if mode in ("identity", "linear"):
        return _embed_linear(X2d, k_dim)
    elif mode == "sine_wiggle":
        return _embed_sine_wiggle(X2d, k_dim, amp=0.25, freq=1.0)
    elif mode == "rff":
        return _embed_rff(X2d, k_dim, freq=1.0)
    elif mode == "radial":
        return _embed_radial(X2d, k_dim)
    else:
        raise ValueError(f"unknown embedding mode: {mode}")




# --------------------------------- nd OT samplers -------------------------------------
# All return torch.Tensor [n,2] on current device/dtype.
@torch.no_grad()
def sample_two_moons(n, gap=0.5, rad=1.0, noise=0.08):
    n1 = n//2; n2 = n - n1
    u1 = torch.rand(n1, device=device, dtype=TDTYPE) * math.pi
    u2 = torch.rand(n2, device=device, dtype=TDTYPE) * math.pi
    x1 = torch.stack([rad*torch.cos(u1), rad*torch.sin(u1)], dim=1)
    x2 = torch.stack([rad*(1.0-torch.cos(u2)), -rad*torch.sin(u2)-gap], dim=1)
    X  = torch.cat([x1, x2], dim=0)
    if noise>0: X = X + noise*torch.randn_like(X)
    return X

@torch.no_grad()
def sample_spiral(n, a=0.5, b=0.25, tmin=0.0, tmax=4.0*math.pi, noise=0.08):
    t = tmin + (tmax - tmin)*torch.rand(n, device=device, dtype=TDTYPE)
    r = a + b*t
    X = torch.stack([r*torch.cos(t), r*torch.sin(t)], dim=1)
    if noise>0: X = X + noise*torch.randn_like(X)
    return X

@torch.no_grad()
def sample_rings(n, radii=(1.0, 2.0, 3.0), sigma_r=0.08):
    radii = torch.tensor(radii, device=device, dtype=TDTYPE)
    idx = torch.randint(0, radii.numel(), (n,), device=device)
    R = radii[idx] + sigma_r*torch.randn(n, device=device, dtype=TDTYPE)
    th = 2*math.pi*torch.rand(n, device=device, dtype=TDTYPE)
    X  = torch.stack([R*torch.cos(th), R*torch.sin(th)], dim=1)
    return X

@torch.no_grad()
def sample_checker_grid(n, cells=4, fill_frac=0.98, jitter=0.01, span=4.0):
    i = torch.randint(0, cells, (n,), device=device)
    j = torch.randint(0, cells, (n,), device=device)
    parity = (i + j) % 2
    j = (j + parity) % cells  # shift into even parity
    cell = span / float(cells)
    centers = torch.stack([i, j], dim=1).to(TDTYPE) + 0.5
    U = (torch.rand(n, 2, device=device, dtype=TDTYPE) - 0.5) * (fill_frac * cell)
    X = (-span/2.0) + centers * cell + U
    if jitter>0: X = X + jitter*torch.randn_like(X)
    return X

@torch.no_grad()
def sample_checker_stripes(n, span=4.0, noise=0.08):
    x1 = (torch.rand(n, device=device, dtype=TDTYPE) - 0.5) * span
    x2 = (torch.rand(n, device=device, dtype=TDTYPE) - 0.5) * span
    x2 = x2 + ((torch.floor(x1) % 2) * (span/4.0))
    X  = torch.stack([x1, x2], dim=1)
    if noise>0: X = X + noise*torch.randn_like(X)
    return X

@torch.no_grad()
def sample_pinwheel(n, radial_std=0.25, tangential_std=0.05, n_arms=5, rate=0.25):
    k = torch.randint(0, n_arms, (n,), device=device)
    r = radial_std*torch.randn(n, device=device, dtype=TDTYPE) + 1.0
    base = k.to(TDTYPE) * (2.0*math.pi/n_arms) + rate*torch.randn(n, device=device, dtype=TDTYPE)
    X = torch.stack([r*torch.cos(base), r*torch.sin(base)], dim=1)
    noise = torch.randn(n, 2, device=device, dtype=TDTYPE)
    c, s = torch.cos(base), torch.sin(base)
    R = torch.stack([torch.stack([c, -s], dim=1),
                     torch.stack([s,  c], dim=1)], dim=1)  # (n,2,2)
    tang = torch.einsum('nij,nj->ni', R, noise) * tangential_std
    return X + tang

@torch.no_grad()
def sample_scurve(n, tmin=-math.pi, tmax=math.pi, noise=0.08):
    t = tmin + (tmax - tmin)*torch.rand(n, device=device, dtype=TDTYPE)
    x = t
    y = torch.sin(t) + 0.25*torch.sin(3.0*t)
    X = torch.stack([x, y], dim=1)
    if noise>0: X = X + noise*torch.randn_like(X)
    return X

@torch.no_grad()
def sample_eight_gaussians(n, radius=4.0, std=0.10, weights=None):
    ang = torch.linspace(0.0, 2.0*math.pi, 9, device=device, dtype=TDTYPE)[:-1]
    means = torch.stack([radius*torch.cos(ang), radius*torch.sin(ang)], dim=1)  # (8,2)
    if weights is None:
        w = torch.full((8,), 1/8, device=device, dtype=TDTYPE)
    else:
        w = torch.tensor(weights, device=device, dtype=TDTYPE)
        w = w / (w.sum() + 1e-12)
    comp = torch.multinomial(w, num_samples=n, replacement=True)  # (n,)
    mu = means[comp]                                             # (n,2)
    return mu + std*torch.randn(n, 2, device=device, dtype=TDTYPE)


# --------------------------- NEW: line target ---------------------------
@torch.no_grad()
def sample_line(
    n: int,
    *,
    length: float = 6.0,     # total extent along x, centered at 0: x ~ U[-length/2, length/2]
    fuzz_y: float = 0.02,    # tiny vertical noise -> almost all variance in x
    fuzz_x: float = 0.0,     # usually 0; set small (e.g. 0.01) if you want to break exact uniformity
):
    # uniform x on a long line
    x = (torch.rand(n, 1, device=device, dtype=TDTYPE) - 0.5) * length
    # tiny vertical fuzz
    y = fuzz_y * torch.randn(n, 1, device=device, dtype=TDTYPE)

    if fuzz_x > 0.0:
        x = x + fuzz_x * torch.randn_like(x)
    return torch.cat([x, y], dim=1)


def sample_rose_knot(
    n,
    k: int = 9,                 # number of petals (odd gives k petals; even gives 2k)
    R: float = 1.25,            # base radius (≈ Gaussian scale)
    alpha: float = 0.6,         # petal amplitude (0<alpha<1)
    turns: float = 2.0,         # how many full wraps around the origin
    noise: float = 0.06,        # overall noise magnitude
    aniso: float = 2.0          # tangential vs radial noise ratio (>1 => thinner petals)
):
    """
    Adversarial 'rose-knot' distribution to maximize independent-coupling crossings.
    Polar param: r(θ) = R * (1 + alpha * cos(k θ)).
    θ ~ Uniform[0, 2π * turns], then add anisotropic (tangent-heavy) noise.

    Typical radius range: R*(1-alpha) .. R*(1+alpha).
    Defaults give ~0.5 .. ~2.0, i.e., near standard Gaussian scale.
    """
    # angles across multiple wraps
    theta = (2.0 * math.pi * turns) * torch.rand(n, device=device, dtype=TDTYPE)

    # rose radius
    r = R * (1.0 + alpha * torch.cos(k * theta))

    # base points on the curve
    x = r * torch.cos(theta)
    y = r * torch.sin(theta)
    base = torch.stack([x, y], dim=1)

    # unit radial & tangential directions
    ur = torch.stack([torch.cos(theta), torch.sin(theta)], dim=1)            # (n,2)
    ut = torch.stack([-torch.sin(theta), torch.cos(theta)], dim=1)           # (n,2)

    # anisotropic noise: thin in radial, fatter along tangent
    radial_std = noise
    tang_std   = noise * aniso
    eps_r = radial_std * torch.randn(n, 1, device=device, dtype=TDTYPE)
    eps_t = tang_std   * torch.randn(n, 1, device=device, dtype=TDTYPE)

    X = base + eps_r * ur + eps_t * ut
    return X


# --------------------------- NEW: Sierpiński triangle target ---------------------------
@torch.no_grad()
def sample_sierpinski(
    n: int,
    *,
    burn_in: int = 20,      # mixing steps (contractive, so this is plenty)
    iters: int = 20,        # additional iterations; final state is sampled
    scale: float = 2.8,     # centers to origin and scales to ~Gaussian radius
    noise: float = 0.03,    # small jitter to thicken filaments
):
    """
    Sierpiński triangle via a 3-map IFS:
      f_i(x) = 0.5*(x + v_i), i in {1,2,3}, with equilateral-triangle vertices.
    We take 'burn_in + iters' contractive steps in batch, then center & scale.

    The default (scale≈2.8) puts the outer radius ~1.6, i.e., close to N(0,I) scale.
    """
    # Equilateral triangle vertices (unit side)
    v = torch.tensor([
        [0.0, 0.0],
        [1.0, 0.0],
        [0.5, math.sqrt(3.0)/2.0],
    ], device=device, dtype=TDTYPE)

    # Start anywhere (zeros is fine; contraction kills init quickly)
    x = torch.zeros(n, 2, device=device, dtype=TDTYPE)

    steps = burn_in + iters
    for _ in range(steps):
        idx = torch.randint(0, 3, (n,), device=device)
        x = 0.5 * (x + v[idx])

    # Center at triangle centroid and scale to ~Gaussian-ish spread
    centroid = torch.tensor([0.5, math.sqrt(3.0)/6.0], device=device, dtype=TDTYPE)
    x = (x - centroid) * scale

    # Thin isotropic noise to avoid degenerate filaments
    if noise > 0:
        x = x + noise * torch.randn_like(x)

    return x



# ---------------------------- TARGET toggle & source ----------------------------
TARGET = "moons"  # {"moons","spiral","rings","checker",...,"sierpinski"}

# --- NEW: optional global whitening of the *embedded* target ---
TARGET_WHITEN = False
TARGET_MEAN = None          # (1, K)
TARGET_WHITEN_MAT = None    # (K, K) inverse sqrt of cov
TARGET_UNWHITEN_MAT = None   # (K, K)   = sqrt, used only for plotting/eval


def set_target(name: str):
    global TARGET
    TARGET = str(name).lower().strip()

def sample_source_torch(n, D=2):
    return torch.randn(n, D, device=device, dtype=TDTYPE)

# ---- base 2-D target (unchanged) ----
def _sample_target_2d(n):
    key = TARGET
    if key in ("moons", "two_moons", "two-moons"):      return sample_two_moons(n)
    if key == "spiral":                                 return sample_spiral(n)
    if key in ("rings","concentric"):                   return sample_rings(n)
    if key in ("checker","checkerboard","checker_grid"):return sample_checker_grid(n)
    if key in ("checker_stripes","checker-legacy"):     return sample_checker_stripes(n)
    if key == "pinwheel":                               return sample_pinwheel(n)
    if key in ("scurve","s-curve","s_curve"):           return sample_scurve(n)
    if key in ("8g","8gaussians","eight_gaussians"):    return sample_eight_gaussians(n)
    if key in ("rose_knot","rose","flower"):            return sample_rose_knot(n)
    if key in ("sierpinski","gasket","tri_gasket"):     return sample_sierpinski(n)
    if key in ("line","long_line","anisotropic_line"):   return sample_line(n)
    return sample_two_moons(n)

@torch.no_grad()
def sample_target_torch(
    n,
    *,
    embedding_mode: str = None,
    k_dim: int = None,
    _skip_whiten: bool = False,
):
    mode = EMBEDDING_MODE if embedding_mode is None else embedding_mode
    K    = EMBEDDING_DIM  if k_dim is None          else int(k_dim)

    if TARGET_WHITEN:
        print(">>> WARNING: whitening active in sample_target_torch")

    X2 = _sample_target_2d(n)
    if K == 2 and (mode in ("identity","",None)):
        X = X2
    else:
        X = embed_to_k(X2, mode=mode, k_dim=K)

    # keep old behavior, but now we can forcibly skip it:
    if (not _skip_whiten) and TARGET_WHITEN and (TARGET_MEAN is not None) and (TARGET_WHITEN_MAT is not None):
        X = (X - TARGET_MEAN) @ TARGET_WHITEN_MAT

    return X


@torch.no_grad()
def fit_target_whitener(
    num: int = 200_000,
    *,
    embedding_mode: str | None = None,
    k_dim: int | None = None,
    eps: float = 1e-6,
):
    global TARGET_WHITEN, TARGET_MEAN, TARGET_WHITEN_MAT, TARGET_UNWHITEN_MAT

    X = sample_target_torch(
        num,
        embedding_mode=embedding_mode,
        k_dim=k_dim,
        _skip_whiten=True,          # make sure we fit on the raw embedded target
    )
    m = X.mean(0, keepdim=True)
    Xc = X - m
    C = (Xc.T @ Xc) / (X.shape[0] - 1)

    evals, evecs = torch.linalg.eigh(C)
    inv_sqrt = evecs @ torch.diag((evals.clamp_min(eps)).rsqrt()) @ evecs.T
    sqrt     = torch.linalg.inv(inv_sqrt)   # <--- this is what we'll use to unwhiten

    TARGET_MEAN         = m
    TARGET_WHITEN_MAT   = inv_sqrt
    TARGET_UNWHITEN_MAT = sqrt
    TARGET_WHITEN       = False


@torch.no_grad()
def maybe_unwhiten_target(X: torch.Tensor) -> torch.Tensor:
    if (
        TARGET_WHITEN
        and (TARGET_UNWHITEN_MAT is not None)
        and (TARGET_MEAN is not None)
    ):
        return X @ TARGET_UNWHITEN_MAT + TARGET_MEAN
    return X


def make_pairs_random(n):
    """
    Return (x0, x1, None) where x0 ~ N(0, I_K), x1 is embedded target in R^K.
    """
    K = EMBEDDING_DIM
    x0 = sample_source_torch(n, D=K)
    x1 = sample_target_torch(n)     # uses global EMBEDDING_MODE/DIM
    return x0, x1, None



# --------------------------------- Metrics (nd) ---------------------------------------
@torch.no_grad()
def mmd_rbf_nd(x: torch.Tensor, y: torch.Tensor, sigma=None, max_n:int = 8192):
    """
    Unbiased MMD with Gaussian kernel in R^d. Subsamples to avoid OOM.
    Returns scalar float.
    """
    x = x.reshape(x.size(0), -1); y = y.reshape(y.size(0), -1)
    if x.size(0) > max_n: x = x[torch.randint(0, x.size(0), (max_n,), device=x.device)]
    if y.size(0) > max_n: y = y[torch.randint(0, y.size(0), (max_n,), device=y.device)]
    n, m = x.size(0), y.size(0)

    if sigma is None:
        take = min(3000, n + m)
        xy = torch.cat([x, y], dim=0)
        sel = torch.randint(0, xy.size(0), (take,), device=xy.device)
        pd = torch.cdist(xy[sel], xy[sel], p=2)
        sigma = torch.median(pd[pd>0]).clamp(min=1e-4)
    gamma = 1.0 / (2.0 * sigma**2)

    Kxx = torch.exp(-gamma * torch.cdist(x, x, p=2).pow(2))
    Kyy = torch.exp(-gamma * torch.cdist(y, y, p=2).pow(2))
    Kxy = torch.exp(-gamma * torch.cdist(x, y, p=2).pow(2))
    mmd2 = (Kxx.sum() - torch.diagonal(Kxx).sum())/(n*(n-1) + 1e-12) \
         + (Kyy.sum() - torch.diagonal(Kyy).sum())/(m*(m-1) + 1e-12) \
         - 2.0 * Kxy.mean()
    return float(mmd2.clamp(min=0).sqrt().detach().cpu())

@torch.no_grad()
def sliced_w2(x: torch.Tensor, y: torch.Tensor, L: int = 128, max_n: int | None = None):
    """
    Sliced Wasserstein-2: average 1D W2 over random projections u ~ Unif(S^{d-1}).
    If max_n is provided, subsample both x and y to at most max_n points.
    """
    x = x.reshape(x.size(0), -1); y = y.reshape(y.size(0), -1)
    n = min(x.size(0), y.size(0))
    if (max_n is not None) and (n > max_n):
        idx = torch.randperm(n, device=x.device)[:max_n]
        x = x[idx]; y = y[idx]
        n = max_n
    else:
        x = x[:n]; y = y[:n]
    d = x.size(1)
    u = torch.randn(L, d, device=x.device, dtype=x.dtype)
    u = u / (u.norm(dim=1, keepdim=True) + 1e-12)
    xs = (x @ u.T).sort(dim=0).values     # (n,L)
    ys = (y @ u.T).sort(dim=0).values
    w2_per = torch.mean((xs - ys).pow(2), dim=0).sqrt()  # (L,)
    return float(w2_per.mean().detach().cpu())


# ---------------------------- 3D crossings (t on X-axis) ----------------------------
from matplotlib import cm
from matplotlib.colors import Normalize
from mpl_toolkits.mplot3d import Axes3D  # noqa: F401


def _set_pane_color(ax, axis: str, rgba):
    try:
        getattr(ax, f"{axis}axis").pane.set_facecolor(rgba)  # mpl ≥ 3.7
    except Exception:
        getattr(ax, f"w_{axis}axis").set_pane_color(rgba)    # back-compat
        getattr(ax, f"w_{axis}axis").set_pane_color(rgba)



@torch.no_grad()
def plot_crossings_proj(
    P: torch.Tensor,
    model_or_sampler=None, *,
    pairs_mode="encoder",
    n_pairs=60_000,
    subset_lines=160,
    subset_strategy="pca",
    line_indices=None,
    plane_mode="scatter",
    bins=220,
    midplane=False, mid_t=0.5,
    mid_bins=180,
    density_gamma=0.4,
    cmap_ref="Blues", cmap_tgt="Oranges", cmap_mid="Purples",
    line_color_mode="target_angle_turbo",
    solid_line_color="#7CFC00",
    line_alpha=0.5, line_width=.5, line_glow=False,
    hsv_sat=0.95, hsv_val=0.95,
    bg="white",
    view_elev=12, view_azim=185,
    seed=None,
    pairs=None,
    title=None,
    save_path=None, show=True,
    name_for_console="crossings(P)",
    t_inset_ref: float = 0.0,
    t_inset_tgt: float = -0.02,
    mark_hits: bool = True,
    hit_ms: float = 1.0, hit_alpha: float = 0.8, hit_mew: float = 1.0, hit_color: str = "k",
    iso_extent_std: float = 3.5,
    iso_ring_levels: tuple = (1.0, 2.0, 3.0),
):
    import numpy as np, matplotlib.pyplot as plt, matplotlib.cm as cm
    import matplotlib.patheffects as pe
    from matplotlib.colors import PowerNorm

    if seed is not None:
        np.random.seed(seed); torch.manual_seed(seed)

    if pairs is not None:
          x_ref, x_tgt = pairs
    else:
        if pairs_mode == "encoder":
            assert hasattr(model_or_sampler, "Enc"), "encoder pairs require AVRC model"
            x1 = sample_target_torch(n_pairs)
            enc_out = model_or_sampler.Enc(x1)

            if isinstance(enc_out, tuple):
                if len(enc_out) == 3:
                    mu, logv, _ = enc_out
                elif len(enc_out) == 2:
                    mu, logv = enc_out
                else:
                    raise ValueError(f"[crossings][debug] unexpected tuple len {len(enc_out)} from Enc(...)")
            else:
                mu = enc_out
                logv = torch.zeros_like(mu)

            eps = torch.randn_like(mu)
            x_ref = mu + torch.exp(0.5 * logv) * eps   # z0
            x_tgt = mu                                 # z1

    # project to 2D
    Xr = project_nd(x_ref, P).detach().cpu().numpy()
    Xt = project_nd(x_tgt, P).detach().cpu().numpy()

    # ---- everything below is same as yours, just relabelled where t=1 used to be "target" ----
    from matplotlib import cm as _cm
    plt.style.use("default")
    fig = plt.figure(figsize=(11.5, 6.8))
    ax  = fig.add_subplot(111, projection="3d")
    ax.set_facecolor(bg)
    tickc = "white" if bg == "black" else "black"
    if bg == "black":
        fig.patch.set_facecolor("black")
        _set_pane_color(ax, 'x', (0, 0, 0, 0))
        _set_pane_color(ax, 'y', (0, 0, 0, 0))
        _set_pane_color(ax, 'z', (0, 0, 0, 0))
        for spine in ax.spines.values(): spine.set_color("white")

    ax.view_init(elev=view_elev, azim=view_azim)
    t_lo = min(0.0, 0.0 + t_inset_ref)
    t_hi = max(1.0, 1.0 + t_inset_tgt)
    ax.set_xlim(t_lo, t_hi)

    Q = 0.997
    x1t_min, x1t_max = np.quantile(Xt[:,0], 1-Q), np.quantile(Xt[:,0], Q)
    x2t_min, x2t_max = np.quantile(Xt[:,1], 1-Q), np.quantile(Xt[:,1], Q)
    R = float(iso_extent_std)
    x1min, x1max = min(-R, x1t_min), max(R, x1t_max)
    x2min, x2max = min(-R, x2t_min), max(R, x2t_max)

    ax.set_ylim(x1min, x1max); ax.set_zlim(x2min, x2max)
    ax.set_xlabel("t", color=tickc); ax.set_ylabel("$x_1$", color=tickc); ax.set_zlabel("$x_2$", color=tickc)
    ax.tick_params(colors=tickc)

    def _density_lookup(X, bins):
        H, xe, ye = np.histogram2d(
            X[:, 0], X[:, 1],
            bins=bins,
            range=[[x1min, x1max], [x2min, x2max]],
            density=True,
        )
        # map each point to its bin density
        i1 = np.clip(np.searchsorted(xe, X[:, 0]) - 1, 0, H.shape[0] - 1)
        i2 = np.clip(np.searchsorted(ye, X[:, 1]) - 1, 0, H.shape[1] - 1)
        d = H[i1, i2]
        return H, d


    def _plane_heat(ax, t_const, X, cmap, bins, alpha=0.97):
        H, xedges, yedges = np.histogram2d(X[:,0], X[:,1], bins=bins,
                                           range=[[x1min, x1max],[x2min, x2max]], density=True)
        norm = PowerNorm(gamma=max(1e-3, density_gamma))
        C = _cm.get_cmap(cmap)(norm(H).T)
        yy, zz = np.meshgrid(xedges[:-1], yedges[:-1], indexing="ij")
        tt = np.full_like(yy, float(t_const))
        ax.plot_surface(tt, yy, zz, rstride=1, cstride=1,
                        facecolors=C, shade=False, antialiased=False, linewidth=0, alpha=alpha)
        return norm

    if plane_mode == "heatmap":
        cnr = _plane_heat(ax, 0.0, Xr, cmap_ref, bins=bins, alpha=0.96)
        cnt = _plane_heat(ax, 1.0, Xt, cmap_tgt, bins=bins, alpha=0.96)
        cbr = fig.colorbar(_cm.ScalarMappable(norm=cnr, cmap=cmap_ref), ax=ax, fraction=0.026, pad=0.04)
        cbt = fig.colorbar(_cm.ScalarMappable(norm=cnt, cmap=cmap_tgt), ax=ax, fraction=0.026, pad=0.01)
        cbr.set_label("ref density @ t=0")
        cbt.set_label("encoder latent density @ t=1")   # ### CHANGED
    else:
        # ---- DEBUG: what are we about to histogram? ----
        # use the helper that returns (H, densities) and NOT raw np.histogram2d
        Href, d_ref = _density_lookup(Xr, bins)
        Htgt, d_tgt = _density_lookup(Xt, bins)

        cnr = PowerNorm(gamma=max(1e-3, density_gamma))
        cnt = PowerNorm(gamma=max(1e-3, density_gamma))

        ax.scatter(
            np.full(Xr.shape[0], 0.0), Xr[:, 0], Xr[:, 1],
            c=d_ref, cmap=cmap_ref, norm=cnr,
            s=1.2, alpha=0.65, depthshade=False, zorder=1, rasterized=True,
        )
        ax.scatter(
            np.full(Xt.shape[0], 1.0), Xt[:, 0], Xt[:, 1],
            c=d_tgt, cmap=cmap_tgt, norm=cnt,
            s=1.0, alpha=0.85, depthshade=False, zorder=20, rasterized=True,
        )

        cbr = fig.colorbar(
            _cm.ScalarMappable(norm=cnr, cmap=cmap_ref),
            ax=ax, fraction=0.026, pad=0.04
        )
        cbt = fig.colorbar(
            _cm.ScalarMappable(norm=cnt, cmap=cmap_tgt),
            ax=ax, fraction=0.026, pad=0.01
        )
        cbr.set_label("encoder latent density @ t=0")   # z₀
        cbt.set_label("encoder latent density @ t=1")   # z₁ = μ

        # ---------------- lines (z0 -> z1) ----------------
        # choose which pairs to draw
        if line_indices is not None:
            keep_idx = np.asarray(line_indices, dtype=int)
            keep_idx = keep_idx[(keep_idx >= 0) & (keep_idx < Xr.shape[0])]
            if keep_idx.size == 0:
                keep_idx = np.arange(min(subset_lines, Xr.shape[0]))
        else:
            # pick by displacement in the *projected* space
            disp  = Xt - Xr
            theta = np.arctan2(disp[:, 1], disp[:, 0]) % (2*np.pi)
            length= np.linalg.norm(disp, axis=1)

            if subset_lines >= Xr.shape[0]:
                keep_idx = np.arange(Xr.shape[0])
            elif subset_strategy == "angle_stratified":
                nb = max(8, int(np.sqrt(subset_lines)))
                bins_theta = np.linspace(0, 2*np.pi, nb + 1)
                keep = []
                for b in range(nb):
                    mask = (theta >= bins_theta[b]) & (theta < bins_theta[b+1])
                    cand = np.where(mask)[0]
                    if cand.size == 0:
                        continue
                    k = max(1, int(np.ceil(subset_lines / nb)))
                    sel = cand[np.argsort(length[cand])[-k:]] if cand.size > k else cand
                    keep.append(sel)
                keep_idx = np.unique(np.concatenate(keep))[:subset_lines]
            elif subset_strategy == "longest":
                keep_idx = np.argsort(length)[-subset_lines:]
            else:
                keep_idx = np.random.choice(Xr.shape[0], size=subset_lines, replace=False)

        print(f"[{name_for_console}][dbg] drawing {keep_idx.size} lines")

        turbo = cm.get_cmap("turbo")

        def _color_from_target(x1v):
            if line_color_mode == "solid":
                return solid_line_color
            elif line_color_mode == "target_angle_turbo":
                ang = (np.arctan2(x1v[1], x1v[0]) % (2*np.pi)) / (2*np.pi)
                return turbo(ang)
            else:
                return solid_line_color

        pefx = [pe.Stroke(linewidth=line_width+1.2, foreground="k", alpha=0.85), pe.Normal()] if line_glow else None
        t0_draw = 0.0 + t_inset_ref
        t1_draw = 1.0 + t_inset_tgt

        hits_y, hits_z = [], []
        for i in keep_idx.tolist():
            z0p, z1p = Xr[i], Xt[i]
            col = _color_from_target(z1p)
            ax.plot(
                [t0_draw, t1_draw],
                [z0p[0],  z1p[0]],
                [z0p[1],  z1p[1]],
                color=col,
                alpha=line_alpha,
                lw=line_width,
                linestyle="--",
                dash_capstyle="round",
                path_effects=pefx,
                zorder=5,
                rasterized=True,
            )
            if mark_hits:
                ax.plot([0.0], [z0p[0]], [z0p[1]],
                        marker="x", markersize=hit_ms, markeredgewidth=hit_mew,
                        color=col, alpha=hit_alpha, zorder=8)
                hits_y.append(z1p[0]); hits_z.append(z1p[1])

        if mark_hits and len(hits_y) > 0:
            ax.plot([1.0]*len(hits_y), hits_y, hits_z,
                    linestyle="None", marker="x", markersize=hit_ms, markeredgewidth=hit_mew,
                    color=hit_color, alpha=hit_alpha, zorder=25)


    # ... keep your midplane, line subsampling, and color logic unchanged ...
        # after you set x1min/x1max/x2min/x2max and before `if plane_mode == "heatmap":`

    # when scattering the t=1 points, this is now z₁=μ(x)
    if plane_mode == "scatter":
        ax.scatter(np.full(Xt.shape[0], 1.0), Xt[:,0], Xt[:,1],
                   c=None, cmap=cmap_tgt, s=1.0, alpha=0.85,
                   depthshade=False, zorder=20, rasterized=True)

    # means: reference vs latent
    mr = Xr.mean(axis=0); mt = Xt.mean(axis=0)
    ax.scatter([0.0],[mr[0]],[mr[1]], s=70, c="#00e5ff", edgecolors="k",
               depthshade=False, label="ref mean", zorder=30)
    ax.scatter([1.0],[mt[0]],[mt[1]], s=70, c="#ffd400", edgecolors="k",
               depthshade=False, label="latent mean", zorder=30)   # ### CHANGED
    ax.legend(loc="upper left", facecolor="none", edgecolor=("white" if bg=="black" else "black"))

    ax.set_title(title or "Couplings — encoder z₀ → z₁ (proj)", color=tickc)  # ### CHANGED

    if iso_ring_levels and len(iso_ring_levels) > 0:
        tt = np.linspace(0, 2*np.pi, 600)
        for r in iso_ring_levels:
            yy = r * np.cos(tt); zz = r * np.sin(tt)
            ax.plot(np.zeros_like(tt), yy, zz, color=(1,1,1,0.95), lw=0.9, ls="--", zorder=3)

    Xproj = np.vstack([Xr, Xt]) - np.mean(np.vstack([Xr, Xt]), axis=0, keepdims=True)
    _, _, vh = np.linalg.svd(Xproj, full_matrices=False)
    v = vh[0]
    p0, p1 = Xr @ v, Xt @ v
    m = min(4000, p0.size); I = np.random.choice(p0.size, size=m, replace=False)
    r0 = np.argsort(np.argsort(p0[I])); r1 = np.argsort(np.argsort(p1[I]))
    invs = np.sum(np.sign(r0[:,None]-r0[None,:]) != np.sign(r1[:,None]-r1[None,:]))
    print(f"[{name_for_console}] approx crossing ratio: {invs/(m*(m-1)):.4f} (m={m})")

    if save_path is not None:
        os.makedirs(os.path.dirname(save_path), exist_ok=True)
        fig.savefig(save_path, dpi=160, bbox_inches="tight", facecolor=fig.get_facecolor())
    if show: plt.show()
    else:    plt.close(fig)



# ========================= NEW: RF-on-current-coupling probe ==========================
# Put this in the same cell as AVRC / utilities (after your imports).

# ------------------------------- Generic config (REPLACES) -------------------------------
@dataclass
class AVRCConfig:
    """Configuration for AVRC (Alternating Variational Rectified Flow Critic).

    Time Sampling via Beta Distribution:
        Time is sampled from Beta(1, gamma) where:
        - gamma=1: Uniform distribution on [0,1] (default, full path training)
        - gamma→∞: Concentrates at t=0 (VAE-like behavior)

        Try very large gamma (e.g., 100, 1000) to test if Path-VAE converges like a VAE.

        Examples:
            cfg = AVRCConfig(time_sampling_gamma=1.0)      # Uniform (default)
            cfg = AVRCConfig(time_sampling_gamma=100.0)    # Mostly t≈0
            cfg = AVRCConfig(time_sampling_gamma=10000.0)  # Nearly delta at t=0
    """
    D: int = 2
    rounds: int = 100
    batch: int = 4096
    log_every: int = 10

    enc_hidden: int = 512
    enc_depth: int = 8
    enc_residual_mu: bool = False

    dec_hidden: int = 512
    dec_depth: int = 8
    dec_dropout: float = 0.05

    enc_lr: float = 1e-3
    dec_lr: float = 1e-4
    enc_lr_decay: float = 1.0
    dec_lr_decay: float = 1.0
    enc_weight_decay: float = 0.0
    dec_weight_decay: float = 0.0
    grad_clip: float = 1.0

    pretrain_ae_steps: int = 1 #2000
    pretrain_ae_kl_weight: float = 1.0
    decoder_steps_per_round: int = 25

    organizer_recon_weight: float = 1.0
    organizer_align_weight: float = 0.0
    organizer_kl_weight: float = 1.0

    critic_recon_weight: float = 1.0
    critic_align_weight: float = 0.0

    # how many rounds to ramp 0 → target
    organizer_recon_warmup: int = 0
    organizer_align_warmup: int = 0  # <- set this to e.g. 500
    organizer_kl_warmup: int = 0

    critic_recon_warmup: int = 0
    critic_align_warmup: int = 0

    agg_kl_batch: int = 65536
    target_eval_n: int = 8192

    # crossings / latent viz (now projection-aware)
    k_plot: int = 10
    viz_cross_dir: str = "viz_crossings3d"
    viz_subset_strategy: str = "random"
    viz_pairs: int = 100000
    viz_subset_lines: int = 160
    viz_bins: int = 160
    viz_plane_mode: str = "scatter"
    viz_density_gamma: float = 1.0
    viz_cmap_ref: str = "Blues"
    viz_cmap_tgt: str = "Oranges"
    viz_seed: int = 123
    viz_camera: tuple = (20, -30)

    # projection settings
    viz_proj_mode: str = "pca"
    viz_num_projections: int = 2
    viz_proj_source: str = "target"

    # RF probe
    test_rf_every: int = 100
    test_rf_steps: int = 10000
    test_rf_batch: int = 2048
    test_rf_lr: float = 1e-3
    test_rf_clip: float = 1.0
    test_rf_hidden: int = 128
    test_rf_depth: int = 4
    test_rf_log_every: int = 10000
    test_rf_Ks: tuple = (1, 2, 4, 8)
    test_rf_n: int = 80_000
    test_rf_mmd_max_n: int = 8192
    test_rf_bins: int = 200
    test_rf_outdir: str = "rf_snapshots"
    test_rf_seed: int | None = 777
    test_rf_proj_index: int = 0
    run_posthoc_rf: bool = True

    # latent viz
    viz_latent: bool = True
    viz_latent_color_mode: str = "hsvnd"
    viz_latent_bg: str = "black"
    viz_latent_s: float = 50.0
    viz_latent_alpha: float = 0.75
    viz_latent_rings: bool = True
    viz_latent_ring_levels: tuple = (1.0, 2.0, 3.0)
    viz_latent_points: int = 1000

    # histogram params
    viz_hist: bool = True
    viz_hist_dir: str = "viz/hists"
    viz_hist_n: int = 100000
    viz_hist_bins: int = 160
    viz_hist_gamma: float = 0.42
    viz_hist_vmax_percentile: float = 99.7

    viz_disp_enable: bool = False

    jitter_lambda: float = 0.0
    device: str = "cuda" if torch.cuda.is_available() else "cpu"

    # Time sampling strategy for the decoder
    time_sampling_gamma: float = 1.0  # shape parameter for Beta(1, gamma)
    time_sampling_strategy: str = "uniform"  # {"uniform", "t0_only", "fixed"}
    fixed_time_value: float = 0.5            # used if strategy is "fixed"
    t0_prob: float = 0.0                     # if > 0, sample t=0 with this probability (mixed with uniform)

    log_mmd_max_n: int = 8192
    log_sw2_max_n: int = 4096

    # ---- NEW: loss annealing ----
    # mode: "linear" or "none"
    loss_anneal_mode: str = "linear"




@torch.no_grad()
def sample_init_points(
    n: int,
    mode: str = "gauss",
    *,
    D: int = 2,
    enc: nn.Module | None = None,
    eps: float = 1e-2
):
    """
    z0 ~ q0(. | x1) depending on `mode` in R^D.
    - "gauss"         : N(0, I_D)
    - "encoder"       : reparam(Enc(x1))  (needs enc)
    - "identity_fuzz" : N(x1, eps I_D)
    """
    if mode == "gauss":
        return torch.randn(n, D, device=device, dtype=TDTYPE)

    elif mode == "encoder":
        assert enc is not None, "encoder init requires enc"
        x1 = sample_target_torch(n)            # expected to output (n, D) when you swap in high-D targets
        mu, logv, _ = unpack_encoder_output(enc(x1))
        return reparam(mu, logv)

    elif mode in ("identity_fuzz", "x_fuzz", "id_fuzz"):
        x1 = sample_target_torch(n)
        return x1 + math.sqrt(max(eps, 1e-12)) * torch.randn_like(x1)

    else:
        raise ValueError(f"unknown init mode: {mode}")




# ----------------------------- Dimension-agnostic velocity -----------------------------
class VelocityXD(nn.Module):
    """v(x,t): R^D × [0,1] → R^D"""
    def __init__(self, D=2, hidden=128, depth=4):
        super().__init__()
        self.D = D
        self.net = EnhancedMLP(input_dim=D, output_dim=D, hidden=hidden, depth=depth)
    def forward(self, x, t):
        return self.net(x, t)


class DecoderXD(nn.Module):
    """Decoder: decode z_t with time conditioning back to ambient space."""
    def __init__(self, D=2, hidden=256, depth=6, dropout=0.0):
        super().__init__()
        self.D = int(D)
        self.net = EnhancedMLP(
            input_dim=D,
            output_dim=D,
            hidden=hidden,
            depth=depth,
            dropout=dropout,
        )

    def forward(self, z: torch.Tensor, t: torch.Tensor) -> torch.Tensor:
        return self.net(z, t)


@torch.no_grad()
def _disp_metrics_vec(pred: torch.Tensor, ell: torch.Tensor):
    eps = 1e-8
    resid2 = (pred-ell).pow(2).sum(dim=1)
    ell2   = ell.pow(2).sum(dim=1)
    mse  = float(resid2.mean().detach().cpu())
    nmse = float((resid2/(ell2+eps)).mean().detach().cpu())
    return {"mse": mse, "nmse": nmse}


# ---------------------- RF on arbitrary coupling pairs (generic D) ---------------------
def train_rectified_flow_on_pairs_nd(
    make_pairs_fn,
    *,
    D: int,
    steps=10_000, batch=2048, lr=1e-3, clip=1.0, hidden=128, depth=4, log_every=200,
    midpoints_K: int | None = None, weight_decay: float = 0.0, seed=None
):
    if seed is not None:
        torch_state = torch.random.get_rng_state()
        np_state = np.random.get_state()
        torch.manual_seed(seed); np.random.set_state(np_state)

    Vx = VelocityXD(D=D, hidden=hidden, depth=depth).to(device)
    opt = torch.optim.Adam(Vx.parameters(), lr=lr, betas=(0.9,0.99), weight_decay=weight_decay)

    t0 = time.time()
    for it in range(1, steps+1):
        x0, x1 = make_pairs_fn(batch)                 # (B, D), (B, D)
        if midpoints_K is None:
            t = torch.rand(batch,1, device=device, dtype=TDTYPE)
        else:
            idx = torch.randint(midpoints_K, (batch,), device=device)
            t = ((idx + 0.5)/float(midpoints_K)).view(batch,1).type_as(x0)

        xt  = (1.0 - t)*x0 + t*x1
        ell = (x1 - x0).detach()
        pred= Vx(xt, t)
        loss= F.mse_loss(pred, ell)
        opt.zero_grad(set_to_none=True); loss.backward()
        nn.utils.clip_grad_norm_(Vx.parameters(), clip); opt.step()

        if (it % log_every) == 0:
            resid2 = (pred-ell).pow(2).sum(dim=1).mean()
            nmse   = resid2 / (ell.pow(2).sum(dim=1).mean() + 1e-8)
            print(f"[fresh-RF-D] step {it}/{steps}  loss={float(loss):.4f}  NMSE={float(nmse):.4f}  (+{time.time()-t0:.1f}s)")
            t0 = time.time()

    if seed is not None:
        torch.random.set_rng_state(torch_state); np.random.set_state(np_state)

    @torch.no_grad()
    def sampler(n: int, nfe: int, init="gauss", enc=None, fuzz_eps=1e-2):
        x = sample_init_points(n, init, D=D, enc=enc, eps=fuzz_eps)
        dt = 1.0/float(max(nfe,1))
        for i in range(nfe):
            t = torch.full((n,1), (i+0.5)*dt, device=device, dtype=TDTYPE)
            x = x + dt * Vx(x, t)
        return x
    return Vx, sampler



# --------------- RF probe grid via projection (REPLACES _plot_rf_probe_grid_nd) ---------------
@torch.no_grad()
def _plot_rf_probe_grid_proj(
    sampler, enc, Ks, n, P: torch.Tensor, bins=180, out_path=None,
    title="fresh RF probe (proj)",
    cmap="magma",
    gamma=0.42,
    vmax_percentile=99.7,
):
    import os, gc, numpy as np, matplotlib.pyplot as plt, matplotlib as mpl
    from matplotlib.colors import PowerNorm

    try: plt.close('all')
    except Exception: pass
    mpl.rcdefaults()

    with plt.rc_context({
        "figure.facecolor": "black",
        "axes.facecolor":   "black",
        "savefig.facecolor":"black",
        "axes.edgecolor":   "white",
        "axes.labelcolor":  "white",
        "xtick.color":      "white",
        "ytick.color":      "white",
    }):
        if out_path is not None:
            os.makedirs(os.path.dirname(out_path), exist_ok=True)

        # Fixed target, then project
        x_tgt = sample_target_torch(n)
        X = project_nd(x_tgt, P).detach().cpu().numpy()

        q = 0.997
        xlim = (np.quantile(X[:,0], 1-q), np.quantile(X[:,0], q)); xlim = [val*1.2 for val in xlim]
        ylim = (np.quantile(X[:,1], 1-q), np.quantile(X[:,1], q)); ylim = [val*1.2 for val in ylim]
        xlim, ylim = _square_limits(xlim, ylim)

        y_edges = np.linspace(xlim[0], xlim[1], bins+1)
        z_edges = np.linspace(ylim[0], ylim[1], bins+1)
        Ht, *_ = np.histogram2d(X[:,0], X[:,1], bins=[y_edges, z_edges], density=True)

        panels = []
        for K in Ks:
            xe = sampler(n, K, init="encoder", enc=enc)
            He, *_ = np.histogram2d(
                project_nd(xe, P).detach().cpu().numpy()[:,0],
                project_nd(xe, P).detach().cpu().numpy()[:,1],
                bins=[y_edges, z_edges], density=True
            )
            panels.append((K, "init: encoder", He))

            xg = sampler(n, K, init="gauss", enc=enc)
            Hg, *_ = np.histogram2d(
                project_nd(xg, P).detach().cpu().numpy()[:,0],
                project_nd(xg, P).detach().cpu().numpy()[:,1],
                bins=[y_edges, z_edges], density=True
            )
            panels.append((K, "init: gauss", Hg))

        all_vals = np.concatenate([Ht.ravel()] + [H.ravel() for (_, _, H) in panels])
        vmax = np.percentile(all_vals, vmax_percentile)
        norm = PowerNorm(gamma=max(1e-3, float(gamma)), vmin=0.0, vmax=max(1e-9, vmax))

        fig, axs = plt.subplots(len(Ks), 3, figsize=(12.0, 3.0*len(Ks)), sharex=True, sharey=True)
        if len(Ks) == 1:
            axs = np.array([axs])

        for r, K in enumerate(Ks):
            # left target
            ax_t = axs[r, 0]
            ax_t.set_facecolor("black")
            ax_t.imshow(Ht.T, origin="lower", extent=[xlim[0], xlim[1], ylim[0], ylim[1]],
                        cmap=cmap, norm=norm, interpolation="bilinear", alpha=1.0, aspect="equal")
            ax_t.set_title("target", color='w', pad=3)
            if r == len(Ks)-1: ax_t.set_xlabel("proj x", color='w')
            ax_t.set_ylabel("proj y", color='w')
            ax_t.tick_params(color='w', labelcolor='w')

            # model columns
            for c, init_label in enumerate(("init: encoder", "init: gauss"), start=1):
                H = panels[2*r + (c-1)][2]
                ax = axs[r, c]
                ax.set_facecolor("black")
                ax.imshow(H.T, origin="lower", extent=[xlim[0], xlim[1], ylim[0], ylim[1]],
                          cmap=cmap, norm=norm, interpolation="bilinear", alpha=1.0, aspect="equal")
                ax.set_title(f"K={K}  ({init_label})", color='w', pad=3)
                if r == len(Ks)-1: ax.set_xlabel("proj x", color='w')
                if c == 1: ax.set_ylabel("proj y", color='w')
                ax.tick_params(color='w', labelcolor='w')

        fig.suptitle(title, y=0.995, color='w')
        fig.tight_layout()
        if out_path is not None:
            fig.savefig(out_path, dpi=190, bbox_inches="tight", facecolor='black')
        plt.close(fig)

    gc.collect()
    return out_path



# --------------- Encoder mean scatter via projection + optional density (REPLACES) ---------------
@torch.no_grad()
def plot_encoder_means_proj(
    Enc, x1, P: torch.Tensor, *,
    out_path=None,
    color_mode="hsvnd",
    bg="black",
    s=.5, alpha=0.85, edge_lw=0.0,
    add_gaussian_rings=True,
    ring_levels=(1.0, 2.0, 3.0),
    title=None,
    iso_extent_std: float = 3.2,
):
    import numpy as np, os, matplotlib.pyplot as plt
    from matplotlib import colors as mcolors
    import matplotlib.cm as cm

    mu, _, _ = unpack_encoder_output(Enc(x1))
    M2 = project_nd(mu, P).detach().cpu().numpy()
    X2 = project_nd(x1, P).detach().cpu().numpy()

    q = 0.997
    if color_mode == "target_angle_turbo":
        ang = (np.arctan2(X2[:,1], X2[:,0]) % (2*np.pi)) / (2*np.pi)
        colors = cm.get_cmap("turbo")(ang)[:, :3]
    else:
        x1min, x1max = np.quantile(X2[:,0], 1-q), np.quantile(X2[:,0], q)
        x2min, x2max = np.quantile(X2[:,1], 1-q), np.quantile(X2[:,1], q)
        u = np.clip((X2[:,0] - x1min) / (x1max - x1min + 1e-9), 0, 1)
        v = np.clip((X2[:,1] - x2min) / (x2max - x2min + 1e-9), 0, 1)
        hsv = np.stack([u, 0.35 + 0.65*v, np.full_like(u, 0.95)], axis=1)
        colors = mcolors.hsv_to_rgb(hsv)

    R = float(iso_extent_std)
    xlim = (-R, R); ylim = (-R, R)

    plt.style.use("default")
    fig, ax = plt.subplots(figsize=(7.4, 8.2))
    fig.patch.set_facecolor(bg); ax.set_facecolor(bg)
    tickc = "white" if bg == "black" else "black"
    for spine in ax.spines.values(): spine.set_color(tickc)

    ax.scatter(M2[:,0], M2[:,1], s=s, c=colors, alpha=alpha, linewidths=edge_lw, zorder=2)

    if add_gaussian_rings:
        t = np.linspace(0, 2*np.pi, 600)
        for r in ring_levels:
            yy = r * np.cos(t); zz = r * np.sin(t)
            ax.plot(yy, zz, color=(1,1,1,0.9), lw=0.9, ls="--", zorder=3)

    ax.set_xlim(*xlim); ax.set_ylim(*ylim)
    ax.set_aspect('equal', adjustable='box')
    ax.set_xlabel("$\\mu_{P,1}$", color=tickc); ax.set_ylabel("$\\mu_{P,2}$", color=tickc)
    ax.tick_params(colors=tickc)
    ax.set_title(title or "Encoder means μ(x) (projected)", color=tickc, pad=8)

    if out_path:
        os.makedirs(os.path.dirname(out_path), exist_ok=True)
        fig.savefig(out_path, dpi=200, bbox_inches="tight", facecolor=fig.get_facecolor())
    plt.close(fig)
    return out_path




# ------------------ Latent samples scatter via projection (REPLACES old) ------------------
@torch.no_grad()
def plot_encoder_latent_proj(
    Enc, x1, eps, P: torch.Tensor, *,
    out_path=None,
    color_mode="hsvnd",
    bg="black",
    s=.5, alpha=0.75, edge_lw=0.0,
    add_gaussian_rings=True,
    ring_levels=(1.0, 2.0, 3.0),
    title=None,
    iso_extent_std: float = 3.5,
):
    import numpy as np, os, matplotlib.pyplot as plt
    from matplotlib import colors as mcolors
    import matplotlib.cm as cm

    mu, logv, _ = unpack_encoder_output(Enc(x1))
    z  = mu + torch.exp(0.5 * logv) * eps
    Z2 = project_nd(z,  P).detach().cpu().numpy()
    X2 = project_nd(x1, P).detach().cpu().numpy()

    q = 0.997
    R = float(iso_extent_std)
    xlim = (-R, R); ylim = (-R, R)

    if color_mode == "target_angle_turbo":
        ang = (np.arctan2(X2[:,1], X2[:,0]) % (2*np.pi)) / (2*np.pi)
        colors = cm.get_cmap("turbo")(ang)
    else:
        x1min, x1max = np.quantile(X2[:,0], 1-q), np.quantile(X2[:,0], q)
        x2min, x2max = np.quantile(X2[:,1], 1-q), np.quantile(X2[:,1], q)
        u = np.clip((X2[:,0] - x1min) / (x1max - x1min + 1e-9), 0, 1)
        v = np.clip((X2[:,1] - x2min) / (x2max - x2min + 1e-9), 0, 1)
        hsv = np.stack([u, 0.35 + 0.65*v, np.full_like(u, 0.95)], axis=1)
        colors = mcolors.hsv_to_rgb(hsv)

    plt.style.use("default")
    fig, ax = plt.subplots(figsize=(7.4, 8.2))
    fig.patch.set_facecolor(bg); ax.set_facecolor(bg)
    tickc = "white" if bg == "black" else "black"
    for spine in ax.spines.values(): spine.set_color(tickc)

    ax.scatter(Z2[:,0], Z2[:,1], s=s, c=colors, alpha=alpha, linewidths=edge_lw)

    if add_gaussian_rings:
        t = np.linspace(0, 2*np.pi, 600)
        for r in ring_levels:
            yy = r * np.cos(t); zz = r * np.sin(t)
            ax.plot(yy, zz, color=(1,1,1,0.9), lw=0.9, ls="--")

    ax.set_xlim(*xlim); ax.set_ylim(*ylim)
    ax.set_aspect('equal', adjustable='box')
    ax.tick_params(colors=tickc)
    ax.set_title(title or "Encoder latent (projected)", color=tickc, pad=8)

    if out_path:
        os.makedirs(os.path.dirname(out_path), exist_ok=True)
        fig.savefig(out_path, dpi=200, bbox_inches="tight", facecolor=fig.get_facecolor())
    plt.close(fig)
    return out_path


@torch.no_grad()
def make_current_V_sampler(V: nn.Module, *, fuzz_eps: float = 1e-2):
    # Grab the model's ambient dimension (VelocityXD sets .D)
    D = getattr(V, "D", None)
    if D is None:
        raise ValueError("Velocity module must expose attribute .D (ambient dimension).")

    def _sampler(n: int, nfe: int, init: str = "gauss", enc: nn.Module | None = None):
        # Pass D explicitly so 'gauss' init uses the correct ambient dim
        x = sample_init_points(n, init, D=D, enc=enc, eps=fuzz_eps)
        if nfe <= 0:
            return x
        dt = 1.0 / float(max(nfe, 1))
        for i in range(nfe):
            t = torch.full((n, 1), (i + 0.5) * dt, device=device, dtype=TDTYPE)
            x = x + dt * V(x, t)
        return x

    return _sampler

@torch.no_grad()
def _eval_rf_latent_probe_proj(
    rf_latent_sampler,         # callable (n, K, init=..., enc=...) -> z in latent space
    enc,
    Ks,
    n: int = 80_000,
    P: torch.Tensor | None = None,
    out_img: str | None = None,
    tag: str = "RF probe (latent, proj)",
    bins: int = 200,
    cmap: str = "magma",
    gamma: float = 0.42,
    vmax_percentile: float = 99.7,
):
    """
    Same grid as _eval_rf_decoded_probe_proj, but:
      • compares **latent** RF samples directly
      • target = μ₀(x₁)
      • no decoder
      • whitening is forcibly skipped on x₁
    """
    import os, gc, numpy as np, matplotlib.pyplot as plt, matplotlib as mpl
    from matplotlib.colors import PowerNorm

    # ---- latent target: μ₀(x₁) ----
    x_tgt = sample_target_torch(n, _skip_whiten=True).to(device)
    mu0, _, _ = unpack_encoder_output(enc(x_tgt))    # (n, D)
    D = mu0.size(1)

    # projection
    if P is None:
        P = choose_projection_pairs(D, num_pairs=1, mode="random")[0]

    tgt_proj = project_nd(mu0, P).detach().cpu().numpy()
    q = 0.997
    xlim = (np.quantile(tgt_proj[:, 0], 1 - q), np.quantile(tgt_proj[:, 0], q)); xlim = [v * 1.2 for v in xlim]
    ylim = (np.quantile(tgt_proj[:, 1], 1 - q), np.quantile(tgt_proj[:, 1], q)); ylim = [v * 1.2 for v in ylim]
    xlim, ylim = _square_limits(xlim, ylim)

    x_edges = np.linspace(xlim[0], xlim[1], bins + 1)
    y_edges = np.linspace(ylim[0], ylim[1], bins + 1)
    Ht, *_  = np.histogram2d(tgt_proj[:, 0], tgt_proj[:, 1],
                             bins=[x_edges, y_edges], density=True)

    perK_panels = {}
    perK_vals   = {}
    tbl = {"rf_latent_enc": {}, "rf_latent_gauss": {}}

    for K in Ks:
        # RF in latent space, start from encoder z₀
        z_enc = rf_latent_sampler(n, K, init="encoder", enc=enc)
        z_enc_proj = project_nd(z_enc, P).detach().cpu().numpy()
        H_enc, *_ = np.histogram2d(z_enc_proj[:, 0], z_enc_proj[:, 1],
                                   bins=[x_edges, y_edges], density=True)

        # RF in latent space, start from N(0,I)
        z_g = rf_latent_sampler(n, K, init="gauss", enc=enc)
        z_g_proj = project_nd(z_g, P).detach().cpu().numpy()
        H_g, *_ = np.histogram2d(z_g_proj[:, 0], z_g_proj[:, 1],
                                 bins=[x_edges, y_edges], density=True)

        perK_panels[K] = [
            ("latent target μ(x)", Ht),
            (f"K={K} — RF (enc z₀)", H_enc),
            (f"K={K} — RF (N(0,I))", H_g),
        ]
        allv = np.concatenate([Ht.ravel(), H_enc.ravel(), H_g.ravel()])
        perK_vals[K] = allv

        # simple divergences in latent space
        sw2_enc = sliced_w2(z_enc, mu0, L=128, max_n=20_000)
        mmd_enc = mmd_rbf_nd(z_enc, mu0, max_n=8192)
        sw2_g   = sliced_w2(z_g,   mu0, L=128, max_n=20_000)
        mmd_g   = mmd_rbf_nd(z_g,  mu0, max_n=8192)
        tbl["rf_latent_enc"][K]   = (float(sw2_enc), float(mmd_enc))
        tbl["rf_latent_gauss"][K] = (float(sw2_g),   float(mmd_g))

    # ---- plotting ----
    try: plt.close("all")
    except: pass
    mpl.rcdefaults()
    with plt.rc_context({
        "figure.facecolor": "black",
        "axes.facecolor":   "black",
        "savefig.facecolor":"black",
        "axes.edgecolor":   "white",
        "axes.labelcolor":  "white",
        "xtick.color":      "white",
        "ytick.color":      "white",
    }):
        if out_img is not None:
            os.makedirs(os.path.dirname(out_img), exist_ok=True)

        rows = len(Ks); cols = 3
        fig, axs = plt.subplots(rows, cols, figsize=(12.0, 2.9 * rows), sharex=True, sharey=True)
        if rows == 1:
            axs = np.array([axs])

        for r, K in enumerate(Ks):
            vmax = np.percentile(perK_vals[K], vmax_percentile)
            norm = PowerNorm(gamma=max(1e-3, float(gamma)), vmin=0.0, vmax=max(1e-9, vmax))
            for c, (title, H) in enumerate(perK_panels[K]):
                ax = axs[r, c]
                ax.imshow(
                    H.T, origin="lower",
                    extent=[xlim[0], xlim[1], ylim[0], ylim[1]],
                    cmap=cmap, norm=norm, interpolation="bilinear", aspect="equal",
                )
                ax.set_title(title, color="w", pad=3)
                if r == rows - 1: ax.set_xlabel("proj x", color="w")
                if c == 0:        ax.set_ylabel("proj y", color="w")
                ax.tick_params(color="w", labelcolor="w")

        fig.suptitle(tag + " — histograms (latent)", y=0.995, color="w")
        fig.tight_layout()
        if out_img is not None:
            fig.savefig(out_img, dpi=190, bbox_inches="tight", facecolor="black")
        plt.close(fig)

    gc.collect()
    return tbl


@torch.no_grad()
def _eval_rf_decoded_probe_proj(
    rf_decoded_sampler,        # callable (n, K, init=..., enc=...) -> x in ambient
    enc,
    Ks,
    n=80_000,
    P: torch.Tensor | None = None,
    out_img: str | None = None,
    tag: str = "V→Dec probe (proj)",
    bins: int = 200,
    cmap: str = "magma",
    gamma: float = 0.42,
    vmax_percentile: float = 99.7,
    *,
    dec_from_latent=None,      # <--- NEW: e.g. self._decode_latents
    dec_t_value: float = 1.0,  # <--- NEW
):
    import os, gc, numpy as np, matplotlib.pyplot as plt, matplotlib as mpl
    from matplotlib.colors import PowerNorm

    # --- target (explicitly NO whitening) ---
    x_tgt = sample_target_torch(n, _skip_whiten=True).to(device)  # (n,D)
    D = x_tgt.size(1)

    if P is None:
        P = choose_projection_pairs(D, num_pairs=1, mode="random")[0]

    # project target
    tgt_proj = project_nd(x_tgt, P).detach().cpu().numpy()
    q   = 0.997
    xlim = (np.quantile(tgt_proj[:,0], 1-q), np.quantile(tgt_proj[:,0], q)); xlim = [v*1.2 for v in xlim]
    ylim = (np.quantile(tgt_proj[:,1], 1-q), np.quantile(tgt_proj[:,1], q)); ylim = [v*1.2 for v in ylim]
    xlim, ylim = _square_limits(xlim, ylim)

    x_edges = np.linspace(xlim[0], xlim[1], bins+1)
    y_edges = np.linspace(ylim[0], ylim[1], bins+1)
    Ht, *_  = np.histogram2d(tgt_proj[:,0], tgt_proj[:,1], bins=[x_edges, y_edges], density=True)

    # --- COL 2: Enc→Dec on THE SAME x_tgt --------------------------------
    enc_out = enc(x_tgt)
    if isinstance(enc_out, tuple):
        mu = enc_out[0]            # (n,D)
    else:
        mu = enc_out
    if dec_from_latent is None:
        # fallback: use the sampler with K=0, but note: this MAY sample a new batch
        x_encdec = rf_decoded_sampler(n, 0, init="encoder", enc=enc).to(device)
    else:
        x_encdec = dec_from_latent(mu, t_value=dec_t_value).to(device)
    x_encdec_proj = project_nd(x_encdec, P).detach().cpu().numpy()
    H_encdec, *_ = np.histogram2d(
        x_encdec_proj[:,0], x_encdec_proj[:,1],
        bins=[x_edges, y_edges], density=True
    )

    # store per-K panels
    perK_panels = {}
    perK_vals   = {}
    tbl = {
        "encdec":      {},   # (col 2)
        "rf_dec_enc":  {},   # (col 3)
        "rf_dec_gauss":{},   # (col 4)
    }

    # metrics for the true baseline (same x₁)
    base_sw2 = sliced_w2(x_encdec, x_tgt, L=128, max_n=20_000)
    base_mmd = mmd_rbf_nd(x_encdec, x_tgt, max_n=8192)

    for K in Ks:
        # col 3: Dec∘V from encoder latent (z₀)
        x_enc = rf_decoded_sampler(n, K, init="encoder", enc=enc).detach().to(device)
        x_enc_proj = project_nd(x_enc, P).detach().cpu().numpy()
        H_enc, *_ = np.histogram2d(x_enc_proj[:,0], x_enc_proj[:,1],
                                   bins=[x_edges, y_edges], density=True)

        # col 4: Dec∘V from N(0,I)
        x_g = rf_decoded_sampler(n, K, init="gauss", enc=enc).detach().to(device)
        x_g_proj = project_nd(x_g, P).detach().cpu().numpy()
        H_g, *_ = np.histogram2d(x_g_proj[:,0], x_g_proj[:,1],
                                 bins=[x_edges, y_edges], density=True)

        perK_panels[K] = [
            ("target", Ht),                  # col 1
            ("Enc→Dec (t=1)", H_encdec),     # col 2
            (f"K={K} — Dec∘V (enc z₀)", H_enc),  # col 3
            (f"K={K} — Dec∘V (N(0,I))", H_g),    # col 4
        ]
        allv = np.concatenate([Ht.ravel(), H_encdec.ravel(), H_enc.ravel(), H_g.ravel()])
        perK_vals[K] = allv

        # metrics
        sw2_enc = sliced_w2(x_enc, x_tgt, L=128, max_n=20_000)
        mmd_enc = mmd_rbf_nd(x_enc, x_tgt, max_n=8192)
        sw2_g   = sliced_w2(x_g,   x_tgt, L=128, max_n=20_000)
        mmd_g   = mmd_rbf_nd(x_g,  x_tgt, max_n=8192)

        tbl["encdec"][K]       = (float(base_sw2), float(base_mmd))
        tbl["rf_dec_enc"][K]   = (float(sw2_enc),  float(mmd_enc))
        tbl["rf_dec_gauss"][K] = (float(sw2_g),    float(mmd_g))

    # --- plotting: rows = |Ks|, cols = 4 ----------------------------------
    try: plt.close("all")
    except: pass
    mpl.rcdefaults()

    with plt.rc_context({
        "figure.facecolor": "black",
        "axes.facecolor":   "black",
        "savefig.facecolor":"black",
        "axes.edgecolor":   "white",
        "axes.labelcolor":  "white",
        "xtick.color":      "white",
        "ytick.color":      "white",
    }):
        if out_img is not None:
            os.makedirs(os.path.dirname(out_img), exist_ok=True)

        rows = len(Ks); cols = 4
        fig, axs = plt.subplots(rows, cols, figsize=(14.0, 2.9*rows), sharex=True, sharey=True)
        if rows == 1:
            axs = np.array([axs])

        for r, K in enumerate(Ks):
            vmax = np.percentile(perK_vals[K], vmax_percentile)
            norm = PowerNorm(gamma=max(1e-3, float(gamma)), vmin=0.0, vmax=max(1e-9, vmax))
            for c, (title, H) in enumerate(perK_panels[K]):
                ax = axs[r, c]
                ax.imshow(
                    H.T,
                    origin="lower",
                    extent=[xlim[0], xlim[1], ylim[0], ylim[1]],
                    cmap=cmap, norm=norm,
                    interpolation="bilinear", aspect="equal",
                )
                ax.set_title(title, color="w", pad=3)
                if r == rows - 1:
                    ax.set_xlabel("proj x", color="w")
                if c == 0:
                    ax.set_ylabel("proj y", color="w")
                ax.tick_params(color="w", labelcolor="w")

        fig.suptitle(tag + " — histograms (decoded, true Enc→Dec col 2)", y=0.995, color="w")
        fig.tight_layout()
        if out_img is not None:
            fig.savefig(out_img, dpi=190, bbox_inches="tight", facecolor="black")
        plt.close(fig)

    gc.collect()
    return tbl



# ----- RF vs V evaluation via projection (REPLACES _eval_probe_models_2x2) -----
@torch.no_grad()
def _eval_probe_models_proj(
    samplers: dict,             # {"RF": rf_sampler, "V": v_sampler}
    enc, Ks, n=80_000, P: torch.Tensor | None = None,
    mmd_max_n=8192,
    out_img=None, tag="RF vs V (proj)", bins=200,
    cmap="magma", gamma=0.42, vmax_percentile=99.7
):
    import os, gc, numpy as np, matplotlib.pyplot as plt, matplotlib as mpl
    from matplotlib.colors import PowerNorm

    x_tgt = sample_target_torch(n).to(device)   # (n, D)
    x_tgt = maybe_unwhiten_target(x_tgt)        # <--- NEW
    D = x_tgt.size(1)

    if P is None:
        # default: random projection if none supplied
        P = choose_projection_pairs(D, num_pairs=1, mode="random")[0]

    tbl = {m: {"gauss": {}, "encoder": {}} for m in samplers.keys()}

    def _run_one(model_key: str, init: str, K: int):
        x = samplers[model_key](n, K, init=init, enc=enc)  # (n, D)
        x = maybe_unwhiten_target(x)                       # <--- NEW
        w2 = sliced_w2(x, x_tgt, L=128, max_n=20_000)
        mmd= mmd_rbf_nd(x, x_tgt, max_n=mmd_max_n)
        Xp = project_nd(x, P).detach().cpu().numpy()
        return float(w2), float(mmd), Xp


    yx = project_nd(x_tgt, P).detach().cpu().numpy()
    q  = 0.997
    xlim = (np.quantile(yx[:,0], 1-q), np.quantile(yx[:,0], q)); xlim = [val * 1.2 for val in xlim]
    ylim = (np.quantile(yx[:,1], 1-q), np.quantile(yx[:,1], q)); ylim = [val * 1.2 for val in ylim]
    xlim, ylim = _square_limits(xlim, ylim)

    y_edges = np.linspace(xlim[0], xlim[1], bins+1)
    z_edges = np.linspace(ylim[0], ylim[1], bins+1)

    Ht, *_ = np.histogram2d(yx[:,0], yx[:,1], bins=[y_edges, z_edges], density=True)

    preferred_order = ["RF", "V", "Decoder"]
    ordered_models = [name for name in preferred_order if name in samplers]
    ordered_models += [name for name in samplers.keys() if name not in ordered_models]
    order = [(model_key, init) for model_key in ordered_models for init in ("gauss", "encoder")]
    perK_panels = {}
    perK_arrays = {}
    for K in Ks:
        panels = [("target", Ht)]
        flat_vals = [Ht.ravel()]
        for (model_key, init) in order:
            sw2, mmd, x_np = _run_one(model_key, init, K)
            tbl[model_key][init][K] = (sw2, mmd)
            H, *_ = np.histogram2d(x_np[:,0], x_np[:,1], bins=[y_edges, z_edges], density=True)
            panels.append((f"{model_key} ({init})", H))
            flat_vals.append(H.ravel())
        perK_panels[K] = panels
        perK_arrays[K] = np.concatenate(flat_vals)

    hdr = "model/init".ljust(14) + " | " + "  ".join([f"K={K:^3d}  SW2   MMD" for K in Ks])
    print("\n=== probe:", tag, "===\n" + hdr + "\n" + "-"*len(hdr))
    for (model_key, init) in order:
        s = f"{model_key}/{init}".ljust(14) + " | "
        for K in Ks:
            sw2, mmd = tbl[model_key][init][K]
            s += f" {sw2:5.3f} {mmd:5.3f} "
        print(s)
    print()

    try: plt.close('all')
    except Exception: pass
    mpl.rcdefaults()
    with plt.rc_context({
        "figure.facecolor": "black",
        "axes.facecolor":   "black",
        "savefig.facecolor":"black",
        "axes.edgecolor":   "white",
        "axes.labelcolor":  "white",
        "xtick.color":      "white",
        "ytick.color":      "white",
    }):
        if out_img is not None:
            os.makedirs(os.path.dirname(out_img), exist_ok=True)

        rows = len(Ks); cols = 5
        fig, axs = plt.subplots(rows, cols, figsize=(14.0, 2.9*rows), sharex=True, sharey=True)
        if rows == 1: axs = np.array([axs])

        for r, K in enumerate(Ks):
            vmax = np.percentile(perK_arrays[K], vmax_percentile)
            norm = PowerNorm(gamma=max(1e-3, float(gamma)), vmin=0.0, vmax=max(1e-9, vmax))
            for c, (title, H) in enumerate(perK_panels[K]):
                ax = axs[r, c]
                ax.imshow(H.T, origin='lower',
                          extent=[xlim[0], xlim[1], ylim[0], ylim[1]],
                          cmap=cmap, norm=norm, interpolation="bilinear", alpha=1.0, aspect='equal')
                ax.set_title(("target" if c==0 else f"K={K} — {title}"), color='w', pad=3)
                if r == rows-1: ax.set_xlabel("proj x", color='w')
                if c == 0:      ax.set_ylabel("proj y", color='w')
                ax.tick_params(color='w', labelcolor='w')

        fig.suptitle(tag + " — histograms (projected)", y=0.995, color='w')
        fig.tight_layout()
        if out_img is not None:
            fig.savefig(out_img, dpi=190, bbox_inches="tight", facecolor='black')
        plt.close(fig)

    gc.collect()
    return tbl



# ---------------------------------------------------------------------------
# AVRC: Path-VAE with post-hoc rectified flow, Beta(1,γ) time, EMA teacher
# ---------------------------------------------------------------------------
class AVRC:
    """Modern AVRC implementation with Beta time sampling + EMA decoder teacher.

    Goals:
      1. Match Algorithm 1 semantics from the PDF: one time per batch sample,
         t ~ Beta(1, gamma), used by BOTH encoder (organizer) and decoder (critic).
      2. Keep your full logging / viz / RF-probe stack unchanged.
      3. Stabilize alternating training in large-gamma regime via EMA decoder.
    """

    def __init__(self, cfg: AVRCConfig = AVRCConfig()):
        self.cfg = cfg
        self.device = device
        D = cfg.D

        # ---------------------- networks ----------------------
        self.Enc = EncoderX1OnlyPro(
                    D=D,
                    width=cfg.enc_hidden,
                    depth=cfg.enc_depth,
                    residual_mu=cfg.enc_residual_mu,
                    produce_endpoint=False,   # z1 is μ(x) now
                ).to(self.device)


        # main decoder, trained in critic_step
        self.Dec = DecoderXD(
            D=D,
            hidden=cfg.dec_hidden,
            depth=cfg.dec_depth,
            dropout=cfg.dec_dropout,
        ).to(self.device)

        # EMA / teacher decoder = slow copy of Dec used in organizer_step
        # so organizer sees a *frozen-but-differentiable* decoder
        self.use_dec_teacher = True
        self.dec_ema = float(getattr(cfg, "dec_ema", 0.995))
        self.t_eps = float(getattr(self.cfg, "t_eps", 1e-6))
        self.Dec_teacher = DecoderXD(
            D=D,
            hidden=cfg.dec_hidden,
            depth=cfg.dec_depth,
            dropout=cfg.dec_dropout,
        ).to(self.device)
        self.Dec_teacher.load_state_dict(self.Dec.state_dict())
        for p in self.Dec_teacher.parameters():
            p.requires_grad_(False)

        # ---------------------- opt / sched ----------------------
        self.opt_enc = torch.optim.Adam(
            self.Enc.parameters(), lr=cfg.enc_lr, weight_decay=cfg.enc_weight_decay
        )
        self.opt_dec = torch.optim.Adam(
            self.Dec.parameters(), lr=cfg.dec_lr, weight_decay=cfg.dec_weight_decay
        )

        self.enc_scheduler = (
            torch.optim.lr_scheduler.ExponentialLR(self.opt_enc, gamma=cfg.enc_lr_decay)
            if cfg.enc_lr_decay != 1.0
            else None
        )
        self.dec_scheduler = (
            torch.optim.lr_scheduler.ExponentialLR(self.opt_dec, gamma=cfg.dec_lr_decay)
            if cfg.dec_lr_decay != 1.0
            else None
        )

        # ---------------------- logging ----------------------
        self.history = {
            "organizer": [],
            "critic": [],
            "encoder_lr": [],
            "decoder_lr": [],
            "metrics": [],      # <-- new
        }
        # ---------------------- viz / rf state ----------------------
        self.posthoc_rf_sampler = None
        self._path_t_grid: torch.Tensor | None = None
        self._viz_ready = False
        self._viz_x1: torch.Tensor | None = None
        self._viz_eps: torch.Tensor | None = None
        self._viz_keep_idx: np.ndarray | None = None
        self._viz_small_idx: np.ndarray | None = None
        self._viz_proj_pairs: list[torch.Tensor] = []
        self.round_idx = 0

        print(f"Training Path-VAE on {self.device}")

    # ------------------------------------------------------------------
    # time grids (kept for backward compatibility / plotting)
    # ------------------------------------------------------------------
    def _get_t_grid(self) -> torch.Tensor:
        steps = max(2, int(self.cfg.path_steps))
        if (
            self._path_t_grid is None
            or self._path_t_grid.numel() != steps
            or self._path_t_grid.device != self.device
        ):
            self._path_t_grid = torch.linspace(
                0.0, 1.0, steps=steps, device=self.device, dtype=TDTYPE
            )
        return self._path_t_grid

    def _time_weight_grid(self, t_grid: torch.Tensor | None = None) -> torch.Tensor:
        """Return normalized weights over the path timesteps following Beta(1, gamma).
        Kept since some of your old metrics still use it.
        """
        if t_grid is None:
            t_grid = self._get_t_grid()
        gamma = float(self.cfg.time_sampling_gamma)
        if gamma <= 0.0:
            raise ValueError("time_sampling_gamma must be positive")
        if gamma == 1.0:
            return torch.full_like(t_grid, 1.0 / t_grid.numel())

        one_minus_t = torch.clamp(1.0 - t_grid, min=1e-12)
        log_pdf = (gamma - 1.0) * torch.log(one_minus_t)
        log_pdf = log_pdf + math.log(gamma)
        log_pdf = log_pdf - torch.max(log_pdf)
        pdf = torch.exp(log_pdf)
        pdf_sum = torch.sum(pdf)
        if torch.isclose(pdf_sum, torch.tensor(0.0, dtype=pdf.dtype, device=pdf.device)):
            weights = torch.zeros_like(pdf)
            weights[0] = 1.0
            return weights
        return pdf / pdf_sum

    @staticmethod
    def _weighted_path_mse(pred: torch.Tensor, target: torch.Tensor, weights: torch.Tensor) -> torch.Tensor:
        diff2 = (pred - target).pow(2)
        weighted = diff2 * weights
        return weighted.sum(dim=1).mean()

    @torch.no_grad()
    def _get_viz_logging_batch(self, N: int) -> dict[str, torch.Tensor]:
        """
        Single source of truth for *both* PNG histograms and numeric metrics.

        Produces:
          - prior_z:         N(0,I)
          - model_z0:        encoder-sampled latent z0(x)
          - x_tgt_enc:       data that produced model_z0
          - x_dec_model:     Dec(z0(x), t≈0)
          - x_tgt_prior:     fresh data batch (for comparing to decoded prior)
          - x_dec_prior:     Dec(N(0,I), t≈0)
        """
        # row 1
        prior_z = torch.randn(N, self.cfg.D, device=self.device, dtype=TDTYPE)

        # row 2 (and latent row)
        model_z0, x_tgt_enc = self._sample_model_latent(N)
        x_dec_model = self._decode_latents(model_z0, t_value=self.t_eps)

        # row 3
        x_tgt_prior = sample_target_torch(N)
        x_dec_prior = self._decode_latents(prior_z, t_value=self.t_eps)

        return {
            "prior_z": prior_z,
            "model_z0": model_z0,
            "x_tgt_enc": x_tgt_enc,
            "x_dec_model": x_dec_model,
            "x_tgt_prior": x_tgt_prior,
            "x_dec_prior": x_dec_prior,
        }


    # ------------------------------------------------------------------
    # EMA utils
    # ------------------------------------------------------------------
    @torch.no_grad()
    def _hard_sync_teacher(self):
        if not self.use_dec_teacher:
            return
        self.Dec_teacher.load_state_dict(self.Dec.state_dict())

    @torch.no_grad()
    def _ema_update_teacher(self):
        if not self.use_dec_teacher:
            return
        ema = self.dec_ema
        for p_t, p in zip(self.Dec_teacher.parameters(), self.Dec.parameters()):
            p_t.data.lerp_(p.data, 1.0 - ema)

    # ------------------------------------------------------------------
    # sampling helpers
    # ------------------------------------------------------------------
    def _sample_time_beta(self, batch_size: int) -> torch.Tensor:
        """Sample time from Beta(1, gamma) distribution, on device."""
        gamma = float(self.cfg.time_sampling_gamma)
        if gamma <= 0.0:
            raise ValueError("time_sampling_gamma must be positive")

        if abs(gamma - 1.0) < 1e-6:
            return torch.rand(batch_size, 1, device=self.device, dtype=TDTYPE)

        a = torch.tensor(1.0, device=self.device, dtype=TDTYPE)
        b = torch.tensor(gamma, device=self.device, dtype=TDTYPE)
        dist = torch.distributions.Beta(a, b)
        t = dist.rsample((batch_size,)).unsqueeze(1)  # (B,1)
        return t

    def _sample_batch(
        self, B: int, requires_grad_encoder: bool
    ) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:
        x1 = sample_target_torch(B)
        if requires_grad_encoder:
            mu, logv, z1 = unpack_encoder_output(self.Enc(x1))
        else:
            with torch.no_grad():
                mu, logv, z1 = unpack_encoder_output(self.Enc(x1))
        if z1 is None:
            z1 = x1
        eps = torch.randn_like(mu)
        z0 = mu + torch.exp(0.5 * logv) * eps
        return x1, mu, logv, z0, z1

    def _decode_path(
        self, z0: torch.Tensor, z1: torch.Tensor
    ) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
        """Kept for backward compatibility / possible diagnostics."""
        t_grid = self._get_t_grid()
        t = t_grid.view(1, -1, 1)
        z_path = (1.0 - t) * z0.unsqueeze(1) + t * z1.unsqueeze(1)
        z_flat = z_path.reshape(-1, z0.size(1))
        t_flat = t_grid.repeat(z0.size(0)).unsqueeze(-1)
        x_flat = self.Dec(z_flat, t_flat)
        x_path = x_flat.view(z0.size(0), t_grid.numel(), -1)
        return x_path, z_path, t_grid

    def _alignment_target(
        self, reference_path: torch.Tensor, x1: torch.Tensor, t_grid: torch.Tensor
    ) -> torch.Tensor:
        x0 = reference_path[:, 0, :]
        return x0.unsqueeze(1) + t_grid.view(1, -1, 1) * (x1 - x0).unsqueeze(1)

    def _decode_single(self, z0, z1, t, *, use_teacher: bool = False):
        dec = self.Dec_teacher if (use_teacher and self.use_dec_teacher) else self.Dec
        zt = (1.0 - t) * z0 + t * z1
        xhat_t = dec(zt, t)
        xhat_0 = dec(z0, torch.zeros_like(t))  # Algorithm 1 wants EXACT 0 here
        return xhat_t, xhat_0

    def _record_lr(self):
        self.history["encoder_lr"].append(self.opt_enc.param_groups[0]["lr"])
        self.history["decoder_lr"].append(self.opt_dec.param_groups[0]["lr"])

    def _decode_latents(self, z: torch.Tensor, t_value: float | None = None) -> torch.Tensor:
        if t_value is None:
            t_value = self.t_eps
        t = torch.full((z.size(0), 1), float(t_value), device=z.device, dtype=TDTYPE)
        return self.Dec(z, t)

    def organizer_step(self, B: int | None = None) -> dict[str, float]:
        B = B or self.cfg.batch

        # 1–5: sample x1, encode, sample z0, sample t~Beta, form z_t, eval frozen-but-diff decoder
        self.Dec.requires_grad_(False)  # frozen-but-differentiable decoder
        x1, mu, logv, z0, z1 = self._sample_batch(B, requires_grad_encoder=True)

        # t ~ Beta(1, gamma)  (PDF has Unif; we're doing your requested Beta variant)
        t = self._sample_time_beta(B)  # (B,1)

        # g_{\bar φ}(·,·): EMA / teacher
        xhat_t, xhat_0 = self._decode_single(z0, z1, t, use_teacher=True)

        # 6. L_disp = || x1 - xhat_t ||^2
        disp_loss = (x1 - xhat_t).pow(2).sum(dim=1).mean()

        # 7. L_align = 2 < xhat_t - xhat_0, x1 - xhat_0 >
        diff_t0 = xhat_t - xhat_0          # decoder’s step along path
        resid_0 = x1 - xhat_0              # residual to data
        align_loss = 2.0 * (diff_t0 * resid_0).sum(dim=1).mean()

        # 8. L_KL
        kl_loss = kl_normal_diag(mu, logv)

        # 9. L_enc = λ_disp * L_disp + λ_align * L_align + λ_KL * L_KL
        total = (
            self.cfg.organizer_recon_weight * disp_loss
            + self.cfg.organizer_align_weight * align_loss
            + self.cfg.organizer_kl_weight * kl_loss
        )
        # (PDF’s alg.1 doesn’t have the endpoint term here, so we drop it;
        #  if you want it, add + cfg.organizer_endpoint_weight * F.mse_loss(xhat_1, x1))

        self.opt_enc.zero_grad(set_to_none=True)
        total.backward()
        if self.cfg.grad_clip > 0:
            nn.utils.clip_grad_norm_(self.Enc.parameters(), self.cfg.grad_clip)
        self.opt_enc.step()
        if self.enc_scheduler is not None:
            self.enc_scheduler.step()

        self.Dec.requires_grad_(True)

        stats = {
            "recon": float(disp_loss.detach().cpu()),
            "align": float(align_loss.detach().cpu()),
            "kl": float(kl_loss.detach().cpu()),
            "total": float(total.detach().cpu()),
        }
        self.history["organizer"].append(stats)
        return stats


    def critic_step(self, B: int | None = None) -> dict[str, float]:
        B = B or self.cfg.batch

        # 1–2: encoder is frozen, we only use it to get the coupling (constants)
        self.Enc.requires_grad_(False)

        # 1. sample x̃₁ ~ p_data
        x1 = sample_target_torch(B)

        # 2–3. encode, sample z̃₀ ~ N(μ₀, Σ₀)
        with torch.no_grad():
              mu, logv, z1 = unpack_encoder_output(self.Enc(x1))
              eps = torch.randn_like(mu)
              z0 = mu + torch.exp(0.5 * logv) * eps

        # 4. sample t (PDF: Unif; here: Beta(1, γ) as you wanted)
        t   = self._sample_time_beta(B)
        zt  = (1.0 - t) * z0 + t * z1           # = μ + (1 - t)(z0 - μ)  ← shrinking cov
        xhat_t = self.Dec(zt, t)
        recon_loss = F.mse_loss(xhat_t, x1)

        # 6. update φ
        total = self.cfg.critic_recon_weight * recon_loss

        self.opt_dec.zero_grad(set_to_none=True)
        total.backward()
        if self.cfg.grad_clip > 0:
            nn.utils.clip_grad_norm_(self.Dec.parameters(), self.cfg.grad_clip)
        self.opt_dec.step()
        if self.dec_scheduler is not None:
            self.dec_scheduler.step()

        # keep EMA teacher in sync for the *next* encoder round
        self._ema_update_teacher()

        # re-enable encoder for organizer
        self.Enc.requires_grad_(True)

        stats = {
            "recon": float(recon_loss.detach().cpu()),
            "total": float(total.detach().cpu()),
        }
        self.history["critic"].append(stats)
        return stats



    @torch.no_grad()
    def _init_crossings_subset(self):
        if self._viz_ready:
            return
        os.makedirs(self.cfg.viz_cross_dir, exist_ok=True)
        torch.manual_seed(self.cfg.viz_seed)
        np.random.seed(self.cfg.viz_seed)

        self._viz_x1 = sample_target_torch(self.cfg.viz_pairs).detach()
        self._viz_eps = torch.randn(
            self.cfg.viz_pairs, self.cfg.D, device=device, dtype=TDTYPE
        ).detach()

        enc_out = self.Enc(self._viz_x1)

        if isinstance(enc_out, tuple):

            try:
                if len(enc_out) == 3:
                    mu0, logv0, _ = enc_out
                elif len(enc_out) == 2:
                    mu0, logv0 = enc_out
                else:
                    raise ValueError(f"[viz][init][debug] unexpected tuple len {len(enc_out)} from Enc(...)")
            except Exception as e:
                print("[viz][init][error] failed to unpack encoder output:", e)
                raise
        else:
            mu0 = enc_out
            logv0 = torch.zeros_like(mu0)

        z0 = mu0 + torch.exp(0.5 * logv0) * self._viz_eps
        z1 = mu0  # deterministic latent                                        # deterministic latent target

        P_seed = choose_projection_pairs(
            self.cfg.D,
            data_for_pca=self._viz_x1 if self.cfg.viz_proj_mode == "pca" else None,
            num_pairs=1,
            mode=self.cfg.viz_proj_mode,
            seed=self.cfg.viz_seed,
        )[0]

        Xr0p = project_nd(z0, P_seed).detach().cpu().numpy()
        Xt0p = project_nd(z1, P_seed).detach().cpu().numpy()

        N = Xr0p.shape[0]
        L = min(self.cfg.viz_subset_lines, N)
        disp = Xt0p - Xr0p
        theta = np.arctan2(disp[:, 1], disp[:, 0]) % (2 * np.pi)
        length = np.linalg.norm(disp, axis=1)

        if L >= N:
            keep_idx = np.arange(N)
        elif self.cfg.viz_subset_strategy == "angle_stratified":
            nb = max(8, int(np.sqrt(L)))
            bins_theta = np.linspace(0, 2 * np.pi, nb + 1)
            picks = []
            for b in range(nb):
                mask = (theta >= bins_theta[b]) & (theta < bins_theta[b + 1])
                cand = np.where(mask)[0]
                if cand.size == 0:
                    continue
                k = max(1, int(np.ceil(L / nb)))
                sel = cand[np.argsort(length[cand])[-k:]] if cand.size > k else cand
                picks.append(sel)
            keep_idx = np.unique(np.concatenate(picks))[:L]
        elif self.cfg.viz_subset_strategy == "longest":
            keep_idx = np.argsort(length)[-L:]
        else:
            rng = np.random.default_rng(self.cfg.viz_seed ^ 0xA5A5A5)
            keep_idx = rng.choice(N, size=L, replace=False)
        self._viz_keep_idx = keep_idx.astype(int)

        M = min(self.cfg.viz_latent_points, N)
        rng2 = np.random.default_rng(self.cfg.viz_seed ^ 0x5A5A5A)
        self._viz_small_idx = rng2.choice(N, size=M, replace=False).astype(int)

        data_for_pca = None
        if self.cfg.viz_proj_mode == "pca":
            data_for_pca = torch.cat([z0, z1], dim=0)
        self._viz_proj_pairs = choose_projection_pairs(
            self.cfg.D,
            data_for_pca=data_for_pca,
            num_pairs=self.cfg.viz_num_projections,
            mode=self.cfg.viz_proj_mode,
            seed=self.cfg.viz_seed,
        )
        self._viz_ready = True



    def _save_crossings_frame(self, round_idx: int):
        if not self._viz_ready:
            self._init_crossings_subset()

        enc_out = self.Enc(self._viz_x1)

        if isinstance(enc_out, tuple):
            try:
                if len(enc_out) == 3:
                    mu, logv, _ = enc_out
                elif len(enc_out) == 2:
                    mu, logv = enc_out
                else:
                    raise ValueError(f"[viz][save][debug] unexpected tuple len {len(enc_out)} from Enc(...)")
            except Exception as e:
                print("[viz][save][error] failed to unpack encoder output:", e)
                raise
        else:
            if torch.is_tensor(enc_out):
                print("[viz][save][debug] single tensor shape:", tuple(enc_out.shape))
            mu = enc_out
            logv = torch.zeros_like(mu)

        z0 = mu + torch.exp(0.5 * logv) * self._viz_eps  # stochastic start
        z1 = mu                                           # deterministic latent                                        # deterministic latent target

        elev, azim = self.cfg.viz_camera
        for j, P in enumerate(self._viz_proj_pairs):
            out = os.path.join(
                self.cfg.viz_cross_dir, f"cross_{round_idx:05d}_p{j:02d}.png"
            )
            plot_crossings_proj(
                P,
                pairs=(z0, z1),                             # latent → latent
                plane_mode=self.cfg.viz_plane_mode,
                bins=self.cfg.viz_bins,
                subset_lines=len(self._viz_keep_idx),
                subset_strategy=self.cfg.viz_subset_strategy,
                line_indices=self._viz_keep_idx,
                density_gamma=self.cfg.viz_density_gamma,
                cmap_ref=self.cfg.viz_cmap_ref,
                cmap_tgt=self.cfg.viz_cmap_tgt,
                view_elev=elev,
                view_azim=azim,
                title=f"Latent couplings — round {round_idx} — proj {j}",
                save_path=out,
                show=False,
            )


    @torch.no_grad()
    def _save_latent_scatter_frame(self, round_idx: int):
        if not self._viz_ready:
            self._init_crossings_subset()
        idx = torch.as_tensor(self._viz_small_idx, device=device, dtype=torch.long)
        x1_small = self._viz_x1[idx]
        eps_small = self._viz_eps[idx]
        for j, P in enumerate(self._viz_proj_pairs):
            out = os.path.join(
                self.cfg.viz_cross_dir, f"latent_{round_idx:05d}_p{j:02d}.png"
            )
            plot_encoder_latent_proj(
                self.Enc,
                x1_small,
                eps_small,
                P,
                out_path=out,
                color_mode=self.cfg.viz_latent_color_mode,
                bg=self.cfg.viz_latent_bg,
                s=self.cfg.viz_latent_s,
                alpha=self.cfg.viz_latent_alpha,
                add_gaussian_rings=self.cfg.viz_latent_rings,
                ring_levels=self.cfg.viz_latent_ring_levels,
                title=f"Encoder latent (proj {j}) — round {round_idx}",
            )

    @torch.no_grad()
    def _save_latent_mu_frame(self, *, round_idx: int):
        if not self._viz_ready:
            self._init_crossings_subset()
        for j, P in enumerate(self._viz_proj_pairs):
            out_path = os.path.join(
                self.cfg.viz_cross_dir, f"latent_mu_{round_idx:05d}_p{j:02d}.png"
            )
            plot_encoder_means_proj(
                Enc=self.Enc,
                x1=self._viz_x1,
                P=P,
                out_path=out_path,
                color_mode=self.cfg.viz_latent_color_mode,
                bg=self.cfg.viz_latent_bg,
                s=self.cfg.viz_latent_s,
                alpha=self.cfg.viz_latent_alpha,
                add_gaussian_rings=self.cfg.viz_latent_rings,
                ring_levels=self.cfg.viz_latent_ring_levels,
                iso_extent_std=3.2,
                title=f"Encoder means μ(x) — r={round_idx:05d} — proj {j}",
            )

    @torch.no_grad()
    def _save_hist_grid_frame(self, round_idx: int, t_path: tuple[float, ...] = (0.0, .5, 0.75, .875, .9375, 1.0)):
        if not self.cfg.viz_hist:
            return

        import os, numpy as np, matplotlib.pyplot as plt
        from matplotlib.colors import PowerNorm

        os.makedirs(self.cfg.viz_hist_dir, exist_ok=True)

        N         = int(self.cfg.viz_hist_n)
        bins      = int(self.cfg.viz_hist_bins)
        gamma     = float(self.cfg.viz_hist_gamma)
        vmax_pct  = float(self.cfg.viz_hist_vmax_percentile)

        # base batch (z0 from encoder, decoded-at-0, etc.)
        batch = self._get_viz_logging_batch(N)

        # tensors on device
        prior_z      = batch["prior_z"]          # (N,D)   latent target ~ N(0,I)
        model_z0     = batch["model_z0"]         # (N,D)
        x_tgt_enc    = batch["x_tgt_enc"]        # (N,D)
        x_dec_model  = batch["x_dec_model"]      # (N,D) = Dec(z_0, t≈0)
        x_tgt_prior  = batch["x_tgt_prior"]      # (N,D)
        x_dec_prior  = batch["x_dec_prior"]      # (N,D) (we don’t plot right now)

        # --------- latent path using μ_0 from encoder ---------
        mu_0, _, z1_from_enc = unpack_encoder_output(self.Enc(x_tgt_enc))

        decoded_path_xy = []
        for tval in t_path:
            z_t = (1.0 - tval) * model_z0 + tval * mu_0
            t_tensor = torch.full(
                (N, 1),
                float(tval if tval > 0.0 else self.t_eps),
                device=self.device,
                dtype=TDTYPE,
            )
            x_dec_t = self.Dec(z_t, t_tensor)
            decoded_path_xy.append((tval, x_dec_t[:, :2].detach().cpu().numpy()))

        # convert to numpy (first 2 dims)
        prior_z2      = prior_z[:, :2].detach().cpu().numpy()
        model_z0_2    = model_z0[:, :2].detach().cpu().numpy()
        x_tgt_enc_2   = x_tgt_enc[:, :2].detach().cpu().numpy()
        x_dec_model_2 = x_dec_model[:, :2].detach().cpu().numpy()
        x_tgt_pr_2    = x_tgt_prior[:, :2].detach().cpu().numpy()

        # robust square limits
        all_x = [x_tgt_enc_2, x_tgt_pr_2, model_z0_2, x_dec_model_2]
        for _, xy in decoded_path_xy:
            all_x.append(xy)
        all_x = np.concatenate(all_x, axis=0)

        q   = 0.997
        lo  = np.quantile(all_x[:, 0], 1 - q); hi = np.quantile(all_x[:, 0], q)
        xlim = (lo * 1.2, hi * 1.2)
        lo  = np.quantile(all_x[:, 1], 1 - q); hi = np.quantile(all_x[:, 1], q)
        ylim = (lo * 1.2, hi * 1.2)

        def _square_limits(xlim, ylim):
            lo = min(xlim[0], ylim[0])
            hi = max(xlim[1], ylim[1])
            return (lo, hi), (lo, hi)

        xlim, ylim = _square_limits(xlim, ylim)

        x_edges = np.linspace(xlim[0], xlim[1], bins + 1)
        y_edges = np.linspace(ylim[0], ylim[1], bins + 1)

        def _hist2d_xy(xy):
            H, *_ = np.histogram2d(xy[:, 0], xy[:, 1], bins=[x_edges, y_edges], density=True)
            return H

        # base hists
        H_latent_tgt = _hist2d_xy(prior_z2)      # ← the true latent target you wanted
        H_tgt_enc    = _hist2d_xy(x_tgt_enc_2)   # ambient / encoder target
        H_tgt_pr     = _hist2d_xy(x_tgt_pr_2)    # target (prior x)
        H_model_z0   = _hist2d_xy(model_z0_2)
        H_dec_z0     = _hist2d_xy(x_dec_model_2)

        # decoded path hists
        H_path_list = []
        for (tval, xy) in decoded_path_xy:
            H_path_list.append((tval, _hist2d_xy(xy)))

        # assemble up to 8 sample panels
        sample_panels: list[tuple[str, np.ndarray]] = []
        sample_panels.append(("encoder z₀(x)", H_model_z0))
        sample_panels.append(("Dec(z₀(x), t≈0)", H_dec_z0))
        for (tval, Ht) in H_path_list:
            sample_panels.append((f"Dec(z_t,t)  t={tval:.2f}", Ht))
        sample_panels = sample_panels[:8]

        # shared vmax
        all_vals = np.concatenate(
            [H_latent_tgt.ravel(), H_tgt_pr.ravel(), H_tgt_enc.ravel()] +
            [H.ravel() for (_, H) in sample_panels]
        )
        vmax = np.percentile(all_vals, vmax_pct)
        norm = PowerNorm(gamma=max(1e-3, gamma), vmin=0.0, vmax=max(vmax, 1e-9))

        R, C = 4, 4
        fig, axs = plt.subplots(R, C, figsize=(12, 14), sharex=True, sharey=True)
        fig.patch.set_facecolor("black")

        def _imshow(ax, H, title):
            ax.imshow(
                H.T,
                origin="lower",
                extent=[xlim[0], xlim[1], ylim[0], ylim[1]],
                cmap="magma",
                norm=norm,
                interpolation="bilinear",
                aspect="equal",
            )
            ax.set_title(title, color="w", pad=3)
            ax.tick_params(color="w", labelcolor="w")
            ax.set_facecolor("black")

        # -------- fill grid --------
        # row 0, col 0 → latent target (what you asked for)
        _imshow(axs[0, 0], H_latent_tgt, "target (latent N(0,I))")
        # row 0, col 2 → ambient/prior target, keep as before
        _imshow(axs[0, 2], H_tgt_pr, "target (prior x)")

        # rows 1..R-1 left columns: ambient target
        for r in range(1, R):
            _imshow(axs[r, 0], H_tgt_enc, "target (enc x)")
            _imshow(axs[r, 2], H_tgt_pr,  "target (prior x)")

        # right columns: sample slots
        for r in range(R):
            slot_idx = r
            if slot_idx < len(sample_panels):
                title, H = sample_panels[slot_idx]
                _imshow(axs[r, 1], H, title)
            else:
                axs[r, 1].axis("off")

            slot_idx2 = r + 4
            if slot_idx2 < len(sample_panels):
                title, H = sample_panels[slot_idx2]
                _imshow(axs[r, 3], H, title)
            else:
                axs[r, 3].axis("off")

        # labels
        for r in range(R):
            axs[r, 0].set_ylabel("y", color="w")
        for c in range(C):
            axs[R - 1, c].set_xlabel("x", color="w")

        fig.suptitle(f"Hist grids @ round {round_idx}", color="w")
        fig.tight_layout()

        out_path = os.path.join(self.cfg.viz_hist_dir, f"hists_{round_idx:05d}.png")
        fig.savefig(out_path, dpi=170, bbox_inches="tight", facecolor="black")
        plt.close(fig)
        print(f"[viz] hist grid saved → {out_path}")




    @torch.no_grad()
    def _estimate_aggregate_kl_from_z(self, z: torch.Tensor) -> tuple[float, float, float]:
        """
        Given z ~ q(z) (already sampled, e.g. encoder-sampled z0),
        estimate KL( N(m,C) || N(0,I) ) where m,C are empirical.
        """
        z = z.reshape(z.size(0), -1)
        N, D = z.size()
        m = z.mean(dim=0, keepdim=True)                  # (1,D)
        zc = z - m
        C = (zc.T @ zc) / float(N)
        C = C + 1e-6 * torch.eye(D, device=z.device, dtype=z.dtype)  # jitter

        trC = torch.trace(C)
        mm = (m @ m.T).squeeze()
        logdetC = torch.logdet(C)
        kl = 0.5 * (trC + mm - D - logdetC)

        avg_var = torch.mean(torch.diag(C))
        mu_norm = m.norm()

        return float(kl.detach().cpu()), float(mu_norm.detach().cpu()), float(avg_var.detach().cpu())

    @torch.no_grad()
    def _eval_viz_metrics(self, batch: dict) -> dict[str, float]:
        # 1) agg KL from model_z0
        kl_agg, mu_norm, avg_var = self._estimate_aggregate_kl_from_z(batch["model_z0"])

        # 2) decoded encoder latent vs its target
        x_dec_model  = batch["x_dec_model"]
        x_tgt_enc    = batch["x_tgt_enc"]
        mmd_enc = mmd_rbf_nd(x_dec_model, x_tgt_enc, max_n=self.cfg.log_mmd_max_n)
        sw2_enc = sliced_w2(x_dec_model, x_tgt_enc, L=128, max_n=self.cfg.log_sw2_max_n)

        # 3) decoded gaussian vs fresh target
        x_dec_prior  = batch["x_dec_prior"]
        x_tgt_prior  = batch["x_tgt_prior"]
        mmd_gauss = mmd_rbf_nd(x_dec_prior, x_tgt_prior, max_n=self.cfg.log_mmd_max_n)
        sw2_gauss = sliced_w2(x_dec_prior, x_tgt_prior, L=128, max_n=self.cfg.log_sw2_max_n)

        return {
            "agg_kl": kl_agg,
            "agg_mu_norm": mu_norm,
            "agg_avg_var": avg_var,
            "mmd_dec_enc": mmd_enc,
            "sw2_dec_enc": sw2_enc,
            "mmd_dec_gauss": mmd_gauss,
            "sw2_dec_gauss": sw2_gauss,
        }



    # ------------------------------------------------------------------
    # RF probe (UNCHANGED)
    # ------------------------------------------------------------------
    def _make_pairs_encoder_current(self):
        @torch.no_grad()
        def gen(n: int):
            x1 = sample_target_torch(int(n))
            mu, logv, z1 = unpack_encoder_output(self.Enc(x1))
            if z1 is None:
                z1 = x1
            eps = torch.randn_like(mu)
            z0 = mu + torch.exp(0.5 * logv) * eps
            return z0, z1

        return gen


    def _run_rf_probe(self, round_idx: int):
        import math, os, torch
        os.makedirs(self.cfg.test_rf_outdir, exist_ok=True)

        tag = f"V-on-coupling@r{round_idx:05d}"

        v_model, _ = train_rectified_flow_on_pairs_nd(
            make_pairs_fn=self._make_pairs_encoder_current(),
            D=self.cfg.D,
            steps=self.cfg.test_rf_steps,
            batch=self.cfg.test_rf_batch,
            lr=self.cfg.test_rf_lr,
            clip=self.cfg.test_rf_clip,
            hidden=self.cfg.test_rf_hidden,
            depth=self.cfg.test_rf_depth,
            log_every=self.cfg.test_rf_log_every,
            seed=self.cfg.test_rf_seed,
        )

        enc_device = next(self.Enc.parameters()).device
        enc_dtype  = next(self.Enc.parameters()).dtype
        D = self.cfg.D

        @torch.no_grad()
        def _sample_z0(n: int, init: str = "gauss", enc=None):
            if enc is None:
                enc = self.Enc
            if init == "gauss":
                return torch.randn(n, D, device=enc_device, dtype=enc_dtype)
            elif init == "encoder":
                x = sample_target_torch(n, _skip_whiten=True).to(enc_device)
                enc_out = enc(x)
                if isinstance(enc_out, tuple):
                    mu = enc_out[0]
                else:
                    mu = enc_out
                return mu
            else:
                raise ValueError(f"unknown init={init}")

        @torch.no_grad()
        def v_sampler(n: int, K: int, init: str = "gauss", enc=None):
            z = _sample_z0(n, init=init, enc=enc).to(enc_device)
            for k in range(K):
                t = (k + 1) / float(K)
                t_in = torch.full((n, 1), t, device=enc_device, dtype=z.dtype)
                v = v_model(z, t_in)
                z = z + v / float(K)
            return z

        @torch.no_grad()
        def decoded_v_sampler(n: int, K: int, init: str = "gauss", enc=None):
            # K=0 gives Enc→Dec baseline
            z = v_sampler(n, K, init=init, enc=enc)
            x = self._decode_latents(z, t_value=1.0 - self.t_eps)
            return x

        # projection
        P = (
            self._viz_proj_pairs[self.cfg.test_rf_proj_index]
            if getattr(self, "_viz_proj_pairs", None)
            else choose_projection_pairs(self.cfg.D, num_pairs=1)[0]
        )

        img = os.path.join(
            self.cfg.test_rf_outdir,
            f"v_probe_{round_idx:05d}_p{self.cfg.test_rf_proj_index:02d}.png",
        )
        tbl_dec = _eval_rf_decoded_probe_proj(
            rf_decoded_sampler=decoded_v_sampler,
            enc=self.Enc,
            Ks=self.cfg.test_rf_Ks,
            n=self.cfg.test_rf_n,
            P=P,
            out_img=img,
            tag=tag,
            bins=self.cfg.test_rf_bins,
            dec_from_latent=self._decode_latents,     # <--- NEW
            dec_t_value=1.0 - self.t_eps,             # <--- NEW
        )

        img_lat = os.path.join(
            self.cfg.test_rf_outdir,
            f"v_probe_{round_idx:05d}_p{self.cfg.test_rf_proj_index:02d}_latent.png",
        )
        tbl_lat = _eval_rf_latent_probe_proj(
            rf_latent_sampler=v_sampler,
            enc=self.Enc,
            Ks=self.cfg.test_rf_Ks,
            n=self.cfg.test_rf_n,
            P=P,
            out_img=img_lat,
            tag=tag + " (latent)",
            bins=self.cfg.test_rf_bins,
        )

        txt = os.path.join(self.cfg.test_rf_outdir, f"v_probe_{round_idx:05d}.txt")

        encdec   = tbl_dec.get("encdec", {})          # <--- NEW: baseline D(mu,1)
        dec_enc  = tbl_dec.get("rf_dec_enc", {})
        dec_gauss= tbl_dec.get("rf_dec_gauss", {})
        lat_enc  = tbl_lat.get("rf_latent_enc", {})
        lat_gauss= tbl_lat.get("rf_latent_gauss", {})

        Ks = list(self.cfg.test_rf_Ks)

        with open(txt, "w") as f:
            def _out(s=""):
                f.write(s + "\n"); print(s)

            _out(f"=== probe: {tag} ===")
            head = "model/init     |"
            for K in Ks:
                head += f"  K={K:<2}   SW2   MMD"
            _out(head)
            _out("-" * len(head))

            import math
            def _get(tbl, K):
                return tbl.get(K, (float("nan"), float("nan")))
            def _fmt(x):
                return f"{x:0.3f}" if math.isfinite(x) else "  nan"

            rows = [
                ("Enc→Dec",        encdec),
                ("V→Dec/encoder",  dec_enc),
                ("V→Dec/gauss",    dec_gauss),
                ("V(lat)/encoder", lat_enc),
                ("V(lat)/gauss",   lat_gauss),
            ]

            for name, tbl in rows:
                line = f"{name:<14}|"
                for K in Ks:
                    sw2, mmd = _get(tbl, K)
                    line += f"  {_fmt(sw2):>5} {_fmt(mmd):>5}"
                _out(line)


        print(f"[probe] saved: {img}, {img_lat} and {txt}")
        self.posthoc_rf_sampler = decoded_v_sampler
        return decoded_v_sampler



    # ------------------------------------------------------------------
    # training loop (your original, just add EMA sync at top)
    # ------------------------------------------------------------------
    def pretrain_autoencoder(self, steps: int | None = None, progress: bool = True):
        steps = self.cfg.pretrain_ae_steps if steps is None else int(steps)
        if steps <= 0:
            return

        for it in range(1, steps + 1):
            x1 = sample_target_torch(self.cfg.batch)
            mu, logv, z1 = unpack_encoder_output(self.Enc(x1))  # z1 == mu
            eps = torch.randn_like(mu)
            z0 = mu + torch.exp(0.5 * logv) * eps

            # t≈0: decode the noisy latent
            x_hat_stoch = self._decode_latents(z0, t_value=self.t_eps)
            # t≈1: decode the *mean* latent (i.e. the endpoint μ(x))
            x_hat_mean  = self._decode_latents(mu, t_value=1 - self.t_eps)

            recon      = F.mse_loss(x_hat_stoch, x1)
            recon_mean = F.mse_loss(x_hat_mean,  x1)
            kl         = kl_normal_diag(mu, logv)
            loss       = recon + recon_mean + self.cfg.pretrain_ae_kl_weight * kl

            self.opt_enc.zero_grad(set_to_none=True)
            self.opt_dec.zero_grad(set_to_none=True)
            loss.backward()
            if self.cfg.grad_clip > 0:
                nn.utils.clip_grad_norm_(self.Enc.parameters(), self.cfg.grad_clip)
                nn.utils.clip_grad_norm_(self.Dec.parameters(), self.cfg.grad_clip)
            self.opt_enc.step()
            self.opt_dec.step()

            # keep EMA in lockstep during pretrain
            self._ema_update_teacher()

            if progress and (it % 200 == 0 or it == steps):
                print(
                    f"[pretrain AE] step {it}/{steps} "
                    f"recon={float(recon.detach().cpu()):.4f} "
                    f"recon_mean={float(recon_mean.detach().cpu()):.4f} "
                    f"kl={float(kl.detach().cpu()):.4f}"
                )

    def _anneal_loss_weight(self, target: float, step: int, warmup: int, mode: str = "linear") -> float:
        if warmup <= 0 or mode == "none":
            return target
        if step >= warmup:
            return target
        # linear 0 → target
        return target * (step / float(warmup))


    def train(self, rounds: int | None = None, progress: bool = True, seed: int | None = None):
        seed_everything(seed)
        rounds = rounds or self.cfg.rounds

        self.pretrain_autoencoder(progress=progress)
        self._hard_sync_teacher()

        self._init_crossings_subset()
        try:
            self._save_crossings_frame(round_idx=0)
            if self.cfg.viz_latent:
                self._save_latent_scatter_frame(round_idx=0)
                self._save_latent_mu_frame(round_idx=0)
            if self.cfg.viz_hist:
                self._save_hist_grid_frame(round_idx=0)
        except Exception as exc:
            print(f"[warn] initial viz failed: {exc}")

        for r in range(1, rounds + 1):
            # ---- compute annealed weights for this round ----
            oa_recon = self._anneal_loss_weight(
                self.cfg.organizer_recon_weight,
                r,
                self.cfg.organizer_recon_warmup,
                self.cfg.loss_anneal_mode,
            )
            oa_align = self._anneal_loss_weight(
                self.cfg.organizer_align_weight,
                r,
                self.cfg.organizer_align_warmup,
                self.cfg.loss_anneal_mode,
            )
            oa_kl = self._anneal_loss_weight(
                self.cfg.organizer_kl_weight,
                r,
                self.cfg.organizer_kl_warmup,
                self.cfg.loss_anneal_mode,
            )
            cr_recon = self._anneal_loss_weight(
                self.cfg.critic_recon_weight,
                r,
                self.cfg.critic_recon_warmup,
                self.cfg.loss_anneal_mode,
            )
            cr_align = self._anneal_loss_weight(
                self.cfg.critic_align_weight,
                r,
                self.cfg.critic_align_warmup,
                self.cfg.loss_anneal_mode,
            )

            # ---- temporarily patch cfg so existing step() code keeps working ----
            orig_org_recon = self.cfg.organizer_recon_weight
            orig_org_align = self.cfg.organizer_align_weight
            orig_org_kl    = self.cfg.organizer_kl_weight
            orig_cr_recon  = self.cfg.critic_recon_weight
            orig_cr_align  = self.cfg.critic_align_weight

            self.cfg.organizer_recon_weight = oa_recon
            self.cfg.organizer_align_weight = oa_align
            self.cfg.organizer_kl_weight    = oa_kl
            self.cfg.critic_recon_weight    = cr_recon
            self.cfg.critic_align_weight    = cr_align

            # --------- do training steps as before ----------
            dec_stats_list = []
            for _ in range(max(1, int(self.cfg.decoder_steps_per_round))):
                dec_stats_list.append(self.critic_step())
            enc_stats = self.organizer_step()

            # restore cfg to avoid surprises outside this loop
            self.cfg.organizer_recon_weight = orig_org_recon
            self.cfg.organizer_align_weight = orig_org_align
            self.cfg.organizer_kl_weight    = orig_org_kl
            self.cfg.critic_recon_weight    = orig_cr_recon
            self.cfg.critic_align_weight    = orig_cr_align

            dec_avg = {
                key: float(np.mean([stats[key] for stats in dec_stats_list]))
                for key in dec_stats_list[0].keys()
            }
            self._record_lr()

            if progress and (r % self.cfg.log_every == 0):
                # ----- extra recon evals along the latent path -----
                with torch.no_grad():
                    # use a smaller eval batch than viz_hist_n
                    eval_batch = self._get_viz_logging_batch(self.cfg.target_eval_n)
                    x_tgt  = eval_batch["x_tgt_enc"]      # (N,D)
                    z0     = eval_batch["model_z0"]       # (N,D)
                    mu_0, _, _ = unpack_encoder_output(self.Enc(x_tgt))

                    def _recon_at(t: float) -> float:
                        z_t = (1.0 - t) * z0 + t * mu_0
                        t_tensor = torch.full(
                            (x_tgt.size(0), 1),
                            float(t if t > 0.0 else self.t_eps),
                            device=self.device,
                            dtype=TDTYPE,
                        )
                        x_dec = self.Dec(z_t, t_tensor)
                        # MSE to ambient target x_1
                        return torch.mean((x_dec - x_tgt) ** 2).item()

                    recon_t0   = _recon_at(0.0)
                    recon_t50  = _recon_at(0.5)
                    recon_t75  = _recon_at(0.75)
                    recon_t100 = _recon_at(1.0)

                print(
                    f"[{r:05d}] enc: recon {enc_stats['recon']:.4f} "
                    f"align {enc_stats['align']:.4f} "
                    f"kl {enc_stats.get('kl', 0.0):.4f} "
                    f"total {enc_stats['total']:.4f} | "
                    f"dec(avg {self.cfg.decoder_steps_per_round}x): "
                    f"recon {dec_avg['recon']:.4f} total {dec_avg['total']:.4f} | "
                    f"recon@t: 0.00={recon_t0:.4f}, 0.50={recon_t50:.4f}, "
                    f"0.75={recon_t75:.4f}, 1.00={recon_t100:.4f} | "
                    f"weights → org(recon={oa_recon:.3f}, align={oa_align:.3f}, kl={oa_kl:.3f}) "
                    f"dec(recon={cr_recon:.3f}, align={cr_align:.3f})"
                )

                viz_batch = self._get_viz_logging_batch(self.cfg.viz_hist_n)
                eval_metrics = self._eval_viz_metrics(viz_batch)
                self.history["metrics"].append({"round": r, **eval_metrics})

                print(
                    f"        agg-KL≈{eval_metrics['agg_kl']:.4f} "
                    f"(||μ||≈{eval_metrics['agg_mu_norm']:.3f}, avg var≈{eval_metrics['agg_avg_var']:.3f}) | "
                    f"dec(enc)→data: MMD≈{eval_metrics['mmd_dec_enc']:.4f} SW2≈{eval_metrics['sw2_dec_enc']:.4f} | "
                    f"dec(gauss)→data: MMD≈{eval_metrics['mmd_dec_gauss']:.4f} SW2≈{eval_metrics['sw2_dec_gauss']:.4f}"
                )


            if self.cfg.k_plot and r % self.cfg.k_plot == 0:
                try:
                    self._save_crossings_frame(round_idx=r)
                    if self.cfg.viz_latent:
                        self._save_latent_scatter_frame(round_idx=r)
                        self._save_latent_mu_frame(round_idx=r)
                    if self.cfg.viz_hist:
                        self._save_hist_grid_frame(round_idx=r)
                except Exception as exc:
                    print(f"[warn] viz failed at round {r}: {exc}")

            if self.cfg.test_rf_every and r % self.cfg.test_rf_every == 0:
                try:
                    self.posthoc_rf_sampler = self._run_rf_probe(round_idx=r)
                except Exception as exc:
                    print(f"[warn] RF probe failed at round {r}: {exc}")

            self.round_idx += 1

        # ... rest of your final RF probe block unchanged ...

        if self.cfg.run_posthoc_rf:
            enc_training, dec_training = self.Enc.training, self.Dec.training
            self.Enc.eval()
            self.Dec.eval()
            try:
                self.posthoc_rf_sampler = self._run_rf_probe(round_idx=self.round_idx)
            except Exception as exc:  # pragma: no cover
                print(f"[warn] final RF probe failed: {exc}")
            finally:
                if enc_training:
                    self.Enc.train()
                if dec_training:
                    self.Dec.train()


    # ------------------------------------------------------------------
    # sampling
    # ------------------------------------------------------------------
    def sample(self, n: int, nfe: int = 1) -> torch.Tensor:
        z = torch.randn(n, self.cfg.D, device=device, dtype=TDTYPE)
        return self._decode_latents(z)

    def _sample_time(self, batch_size: int) -> torch.Tensor:
         """Sample time values according to cfg.time_sampling_strategy.

         Strategies:
           - 'uniform': t ~ U[0, 1]
           - 't0_only': t = 0 (standard VAE decoder at t=0)
           - 'fixed': t = cfg.fixed_time_value
           - Mixed: if cfg.t0_prob > 0, sample t=0 with that probability, else uniform
         """
         if self.cfg.time_sampling_strategy == "t0_only":
             return torch.zeros(batch_size, 1, device=self.device, dtype=TDTYPE)
         elif self.cfg.time_sampling_strategy == "fixed":
             return torch.full((batch_size, 1), self.cfg.fixed_time_value, device=self.device, dtype=TDTYPE)
         else:  # "uniform" or mixed
             if self.cfg.t0_prob > 0.0:
                 # Mixed: sample t=0 with probability t0_prob, else uniform
                 mask = torch.rand(batch_size, device=self.device) < self.cfg.t0_prob
                 t = torch.rand(batch_size, 1, device=self.device, dtype=TDTYPE)
                 t[mask] = 0.0
                 return t
             else:
                 # Pure uniform
                 return torch.rand(batch_size, 1, device=self.device, dtype=TDTYPE)


    @torch.no_grad()
    def _sample_model_latent(self, n: int) -> tuple[torch.Tensor, torch.Tensor]:
        """x ~ pdata, encode, sample z0. Returns (z0, x)."""
        x = sample_target_torch(n)
        mu, logv, z1 = unpack_encoder_output(self.Enc(x))
        if z1 is None:
            z1 = x
        eps = torch.randn_like(mu)
        z0 = mu + torch.exp(0.5 * logv) * eps
        return z0, x

    @torch.no_grad()
    def _sample_decoded_model_latent(self, n: int) -> tuple[torch.Tensor, torch.Tensor]:
        z0, x = self._sample_model_latent(n)
        x_dec = self._decode_latents(z0, t_value=self.t_eps)
        return x_dec, x

    @torch.no_grad()
    def _sample_decoded_gaussian(self, n: int) -> torch.Tensor:
        z = torch.randn(n, self.cfg.D, device=self.device, dtype=TDTYPE)
        x_dec = self._decode_latents(z, t_value=self.t_eps)
        return x_dec


# ----------------------------- Standard RF (independent) ND ---------------------------
def train_rectified_flow_nd(
    *,
    D: int,
    steps=10000, batch=2048, lr=1e-3, clip=1.0, log_every=200,
    hidden=128, depth=4,
    midpoints_K: int | None = None, weight_decay: float = 0.0, seed: int | None = None
):
    if seed is not None:
        torch_state = torch.random.get_rng_state(); np_state = np.random.get_state()
        torch.manual_seed(seed); np.random.set_state(np_state)

    Vx = VelocityXD(D=D, hidden=hidden, depth=depth).to(device)
    opt = torch.optim.Adam(Vx.parameters(), lr=lr, betas=(0.9, 0.99), weight_decay=weight_decay)

    for it in range(1, steps+1):
        x0 = sample_source_torch(batch, D=D)
        x1 = sample_target_torch(batch)
        if midpoints_K is None:
            t  = torch.rand(batch, 1, device=device, dtype=TDTYPE)
        else:
            idx = torch.randint(midpoints_K, (batch,), device=device)
            t   = ((idx + 0.5) / float(midpoints_K)).view(batch, 1).type_as(x0)
        xt  = (1.0 - t) * x0 + t * x1
        ell = (x1 - x0).detach()
        pred = Vx(xt, t)
        loss = F.mse_loss(pred, ell)
        opt.zero_grad(set_to_none=True); loss.backward()
        nn.utils.clip_grad_norm_(Vx.parameters(), clip); opt.step()

        if (it % log_every) == 0:
            resid2 = (pred-ell).pow(2).sum(dim=1).mean()
            nmse   = resid2 / (ell.pow(2).sum(dim=1).mean() + 1e-8)
            print(f"[RF-D] step {it}/{steps}  loss={float(loss):.4f}  NMSE={float(nmse):.4f}")

    if seed is not None:
        torch.random.set_rng_state(torch_state); np.random.set_state(np_state)

    @torch.no_grad()
    def rf_sampler(n: int, nfe: int):
        x = torch.randn(n, D, device=device, dtype=TDTYPE)
        dt = 1.0/float(max(nfe,1))
        for i in range(nfe):
            t = torch.full((n,1), (i+0.5)*dt, device=device, dtype=TDTYPE)
            x = x + dt * Vx(x, t)
        return x

    return Vx, rf_sampler



# In[32]:


import os, shutil
for _d in ["viz_crossings3d", "rf_snapshots", "training_plots"]:
    shutil.rmtree(_d, ignore_errors=True)
for _d in ["viz_crossings3d", "viz_rf_snapshots", "training_plots"]:
    os.makedirs(_d, exist_ok=True)


# In[38]:


from logging import debug
# =============================== Main + nd Viz / Bench ================================
# Added detailed LOGGING and TIMING to diagnose stalls around benchmark_samplers_nd.
#
# What's new:
#   • benchmark_samplers_nd now logs per-sampler/K timing (sampling, SW2, MMD), throughput,
#     and (if CUDA) memory stats; also supports chunked sampling to avoid spikes.
#   • _plot_heat_grid logs timing; KDE fitting uses capped subsampling (kde_max_n) and
#     contour grid is computed once and reused.
#   • Crossings plot unchanged except for optional logging.
#
# If you still see a stall, likely culprits are:
#   1) very large n with big Ks (lots of forward passes), or
#   2) KDE fit on huge x_tgt, or
#   3) SW2 on all n (now capped via sw2_max_n).
#
# You can lower n, use smaller Ks, or raise chunk_n to spread work.

import os, sys, math, time, numpy as np
import torch
import matplotlib.pyplot as plt
from time import perf_counter as _tic
from sklearn.neighbors import KernelDensity

# ---------- sync helpers ----------
def _sync():
    if torch.cuda.is_available():
        torch.cuda.synchronize()

def _gpu_mem():
    if not torch.cuda.is_available():
        return "(CPU)"
    alloc = torch.cuda.memory_allocated() / 1e9
    reserv= torch.cuda.memory_reserved() / 1e9
    return f"(GPU mem: alloc={alloc:.2f} GB, reserved={reserv:.2f} GB)"


@torch.no_grad()
def avrc_oracle_sampler_torch_nd(model) -> callable:
    def sampler(n: int, nfe: int):
        x1 = sample_target_torch(n)
        mu, logv = model.Enc(x1)
        z = reparam(mu, logv)
        return model._decode_latents(z)

    return sampler


# ----------------------------- AVRC samplers (ND wrappers) ----------------------------
@torch.no_grad()
def avrc_sample_torch_nd(model_or_sampler, n: int, nfe: int = 8) -> torch.Tensor:
    if hasattr(model_or_sampler, "sample"):
        return model_or_sampler.sample(n, nfe)
    if callable(model_or_sampler):
        out = model_or_sampler(n, nfe)
        if not isinstance(out, torch.Tensor):
            raise TypeError("Sampler must return a torch.Tensor.")
        return out
    raise TypeError("Expected AVRC-compatible sampler.")

@torch.no_grad()
def evaluate_model_divergences_nd(model_or_sampler, n=200_000, nfe=8, mmd_max_n=8192, L=128, sw2_max_n=20000):
    x_model = avrc_sample_torch_nd(model_or_sampler, n, nfe)
    x_tgt   = sample_target_torch(n)
    sw2 = sliced_w2(x_model, x_tgt, L=L, max_n=sw2_max_n)
    mmd = mmd_rbf_nd(x_model, x_tgt, max_n=mmd_max_n)
    print(f"[Divergences ND]  SW2≈{sw2:.4f}   MMD≈{mmd:.4f}  (n={n}, K={nfe}, L={L})")
    return sw2, mmd

# ----------------------------- KDE (nd) utilities ------------------------------------
def _fit_kde_nd(X_np: np.ndarray, bw: float | None = None):
    n, d = X_np.shape
    if bw is None:
        std = X_np.std(axis=0, ddof=1) + 1e-8
        bw  = float((n ** (-1.0/(d+4))) * np.mean(std))
        bw  = max(bw, 1e-3)
    kde = KernelDensity(bandwidth=bw, kernel='gaussian'); kde.fit(X_np)
    return kde, bw

def _kde_grid_eval(kde: KernelDensity, xlim, ylim, gridsize=200):
    xs = np.linspace(xlim[0], xlim[1], gridsize)
    ys = np.linspace(ylim[0], ylim[1], gridsize)
    Xg, Yg = np.meshgrid(xs, ys, indexing='xy')
    pts = np.stack([Xg.ravel(), Yg.ravel()], axis=1)
    logp = kde.score_samples(pts).reshape(gridsize, gridsize)
    return Xg, Yg, logp

# ------------------------- Simple wrappers to sample & project -------------------------
@torch.no_grad()
def avrc_sample_torch(model_or_sampler, n: int, nfe: int = 8) -> torch.Tensor:
    # keep exported name but route to ND
    return avrc_sample_torch_nd(model_or_sampler, n=n, nfe=nfe)

# -------------------------- nd heatmap of projected samples ---------------------------
@torch.no_grad()
def plot_output_heatmaps_proj(
    model_or_sampler, P: torch.Tensor, n=200_000, nfe=8, bins=180, target_n=None,
    xlim=None, ylim=None, cmap="magma", title="Model vs Target (proj)",
    gamma: float = 0.42, vmax_percentile: float = 99.7
):
    import numpy as np, matplotlib.pyplot as plt, matplotlib as mpl
    from matplotlib.colors import PowerNorm

    x_model = avrc_sample_torch(model_or_sampler, n=n, nfe=nfe)
    x_model = maybe_unwhiten_target(x_model)  # <--- NEW

    x_tgt = sample_target_torch(n if target_n is None else target_n)
    x_tgt = maybe_unwhiten_target(x_tgt)      # <--- NEW

    xm2 = project_nd(x_model, P).detach().cpu().numpy()
    xt2 = project_nd(x_tgt, P).detach().cpu().numpy()


    if xlim is None or ylim is None:
        q = 0.997
        xlim = xlim or (np.quantile(xt2[:,0], 1-q), np.quantile(xt2[:,0], q))
        xlim = [val * 1.2 for val in xlim]
        ylim = ylim or (np.quantile(xt2[:,1], 1-q), np.quantile(xt2[:,1], q))
        ylim = [val * 1.2 for val in ylim]
        xlim, ylim = _square_limits(xlim, ylim)


    y_edges = np.linspace(xlim[0], xlim[1], bins+1)
    z_edges = np.linspace(ylim[0], ylim[1], bins+1)

    Ht, *_ = np.histogram2d(xt2[:,0], xt2[:,1], bins=[y_edges, z_edges], density=True)
    Hm, *_ = np.histogram2d(xm2[:,0], xm2[:,1], bins=[y_edges, z_edges], density=True)

    all_vals = np.concatenate([Ht.ravel(), Hm.ravel()])
    vmax = np.percentile(all_vals, vmax_percentile)
    norm = PowerNorm(gamma=max(1e-3, float(gamma)), vmin=0.0, vmax=max(1e-9, vmax))

    try: plt.close('all')
    except Exception: pass
    mpl.rcdefaults()
    with plt.rc_context({
        "figure.facecolor": "black",
        "axes.facecolor":   "black",
        "savefig.facecolor":"black",
        "axes.edgecolor":   "white",
        "axes.labelcolor":  "white",
        "xtick.color":      "white",
        "ytick.color":      "white",
    }):
        fig, axs = plt.subplots(1, 2, figsize=(10.8, 4.2), sharex=True, sharey=True)
        ax = axs[0]
        ax.imshow(Ht.T, origin="lower", extent=[xlim[0], xlim[1], ylim[0], ylim[1]],
                  cmap=cmap, norm=norm, interpolation="bilinear", alpha=1.0, aspect="equal")
        ax.set_title("target", color='w', pad=3)
        ax.set_xlabel("proj x", color='w'); ax.set_ylabel("proj y", color='w')
        ax.tick_params(color='w', labelcolor='w')

        ax = axs[1]
        ax.imshow(Hm.T, origin="lower", extent=[xlim[0], xlim[1], ylim[0], ylim[1]],
                  cmap=cmap, norm=norm, interpolation="bilinear", alpha=1.0, aspect="equal")
        ax.set_title(f"model (K={nfe})", color='w', pad=3)
        ax.set_xlabel("proj x", color='w')
        ax.tick_params(color='w', labelcolor='w')

        fig.suptitle(title, y=0.995, color='w')
        fig.tight_layout()
        plt.show()



# ---------------------------- 3D crossings: heatmap planes + cords ----------------------------
from matplotlib import cm
from matplotlib.colors import Normalize
from mpl_toolkits.mplot3d import Axes3D  # noqa: F401 (activates 3D proj)


# ----------------------------- Benchmark grid (3-model, timed) ------------------------
def _sample_in_chunks(sampler, n: int, nfe: int, chunk_n: int):
    """
    Call sampler in chunks to avoid big allocations; returns concatenated Tensor on device.
    """
    outs = []
    done = 0
    while done < n:
        take = min(chunk_n, n - done)
        out = avrc_sample_torch(sampler, n=take, nfe=nfe)  # (take,2)
        outs.append(out)
        done += take
    return torch.cat(outs, dim=0)


def _plot_heat_grid(
    samples_by_nameK: dict, x_tgt: torch.Tensor,
    Ks=(1,2,4,8,16), bins=160, xlim=None, ylim=None, cmap="magma",
    out_dir: str | None = None, prefix: str = "benchnd",
    gamma: float = 0.42, vmax_percentile: float = 99.7
):
    import os, numpy as np, matplotlib.pyplot as plt, matplotlib as mpl
    from matplotlib.colors import PowerNorm

    t0 = _tic()
    names = list(samples_by_nameK.keys())
    R, C = len(Ks), 1 + len(names)   # +1 for TARGET column

    x_tgt_np = x_tgt.detach().cpu().numpy()

    # Robust bounds from target (match probe style)
    if xlim is None or ylim is None:
        q = 0.997
        xlim = xlim or (np.quantile(x_tgt_np[:,0], 1-q), np.quantile(x_tgt_np[:,0], q))
        xlim = [val * 1.2 for val in xlim]
        ylim = ylim or (np.quantile(x_tgt_np[:,1], 1-q), np.quantile(x_tgt_np[:,1], q))
        ylim = [val * 1.2 for val in ylim]

    # 👉 force square data extent
    xlim, ylim = _square_limits(xlim, ylim)

    # Shared edges
    y_edges = np.linspace(xlim[0], xlim[1], bins+1)
    z_edges = np.linspace(ylim[0], ylim[1], bins+1)

    Ht, *_ = np.histogram2d(x_tgt_np[:,0], x_tgt_np[:,1], bins=[y_edges, z_edges], density=True)

    try: plt.close('all')
    except Exception: pass
    mpl.rcdefaults()
    with plt.rc_context({
        "figure.facecolor": "black",
        "axes.facecolor":   "black",
        "savefig.facecolor":"black",
        "axes.edgecolor":   "white",
        "axes.labelcolor":  "white",
        "xtick.color":      "white",
        "ytick.color":      "white",
    }):
        fig, axs = plt.subplots(R, C, figsize=(4.3*C, 3.1*R), sharex=True, sharey=True)
        if R == 1 and C == 1:
            axs = np.array([[axs]])
        elif R == 1:
            axs = np.array([axs])
        elif C == 1:
            axs = np.array([[ax] for ax in axs])

        for r, K in enumerate(Ks):
            row_histos = [Ht.ravel()]
            panels = [("target", Ht)]

            for name in names:
                x_model = samples_by_nameK[name][K].detach().cpu().numpy()
                Hm, *_ = np.histogram2d(x_model[:,0], x_model[:,1], bins=[y_edges, z_edges], density=True)
                panels.append((f"{name}", Hm))
                row_histos.append(Hm.ravel())

            vmax = np.percentile(np.concatenate(row_histos), vmax_percentile)
            norm = PowerNorm(gamma=max(1e-3, float(gamma)), vmin=0.0, vmax=max(1e-9, vmax))

            for c, (title, H) in enumerate(panels):
                ax = axs[r, c] if R > 1 else axs[0, c]
                ax.imshow(
                    H.T, origin="lower",
                    extent=[xlim[0], xlim[1], ylim[0], ylim[1]],
                    cmap=cmap, norm=norm, interpolation="bilinear", alpha=1.0, aspect="equal"
                )
                if c == 0:
                    ax.set_title("target", color='w', pad=3)
                else:
                    ax.set_title(f"K={K} — {title}", color='w', pad=3)
                if r == R-1: ax.set_xlabel("x", color='w')
                if c == 0:   ax.set_ylabel("y", color='w')
                ax.tick_params(color='w', labelcolor='w')

        fig.suptitle("nd histograms by sampler (target in left column)", y=0.995, color='w')
        fig.tight_layout()

        saved_path = None
        if out_dir is not None:
            os.makedirs(out_dir, exist_ok=True)
            saved_path = os.path.join(out_dir, f"{prefix}_hists_{R}x{C}.png")
            fig.savefig(saved_path, dpi=170, bbox_inches="tight", facecolor='black')
            print(f"[heat grid saved] {saved_path}")
        plt.show()

    t3 = _tic()
    print(f"[plot_grid] total draw {t3 - t0:.2f}s  {_gpu_mem()}")
    return saved_path if out_dir is not None else None



# ----------------------------- Benchmark via projection (REPLACES) -----------------------------
@torch.no_grad()
def benchmark_samplers_proj(
    name2sampler: dict,
    P: torch.Tensor,
    Ks=(1,2,4,8),
    n=120_000,
    mmd_max_n=8192,
    plot_hists: bool = True,
    hist_bins: int = 160,
    hist_out_dir: str | None = "bench_hists_proj",
    hist_prefix: str = "bench_proj",
    sw2_L: int = 128,
    sw2_max_n: int | None = 20000,
    sample_chunk_n: int = 40000,
    hist_cmap: str = "magma",
    hist_gamma: float = 0.42,
    hist_vmax_percentile: float = 99.7,
):
    import numpy as np, matplotlib.pyplot as plt, matplotlib as mpl
    from matplotlib.colors import PowerNorm

    print(f"\n=== Projected Sampling quality ===  n={n}, Ks={tuple(Ks)}, sw2_L={sw2_L}, sw2_max_n={sw2_max_n}")

    x_tgt = sample_target_torch(n)
    x_tgt = maybe_unwhiten_target(x_tgt)          # <--- NEW
    Xt2   = project_nd(x_tgt, P).detach().cpu().numpy()

    q = 0.997
    xlim = (np.quantile(Xt2[:,0], 1-q), np.quantile(Xt2[:,0], q)); xlim = [val*1.2 for val in xlim]
    ylim = (np.quantile(Xt2[:,1], 1-q), np.quantile(Xt2[:,1], q)); ylim = [val*1.2 for val in ylim]
    xlim, ylim = _square_limits(xlim, ylim)

    y_edges = np.linspace(xlim[0], xlim[1], hist_bins+1)
    z_edges = np.linspace(ylim[0], ylim[1], hist_bins+1)
    Ht, *_ = np.histogram2d(Xt2[:,0], Xt2[:,1], bins=[y_edges, z_edges], density=True)

    results = {}
    samples_for_plots = {name: {} for name in name2sampler.keys()}

    for name, sampler in name2sampler.items():
        row = name.ljust(34) + " | "
        entry = {}
        for K in Ks:
            x = []
            done = 0
            while done < n:
                take = min(sample_chunk_n, n - done)
                out = avrc_sample_torch_nd(sampler, n=take, nfe=K)   # (take, D)
                x.append(out); done += take
            X = torch.cat(x, dim=0)
            X = maybe_unwhiten_target(X)          # <--- NEW
            sw2 = sliced_w2(X, x_tgt, L=sw2_L, max_n=sw2_max_n)
            mmd = mmd_rbf_nd(X, x_tgt, max_n=mmd_max_n)
            results.setdefault(name, {})[K] = (sw2, mmd)
            row += f" {sw2:5.3f} {mmd:5.3f} "
            samples_for_plots[name][K] = project_nd(X, P).detach().cpu().numpy()
        print(row); print()

    if plot_hists:
        try: plt.close('all')
        except Exception: pass
        mpl.rcdefaults()
        with plt.rc_context({
            "figure.facecolor": "black",
            "axes.facecolor":   "black",
            "savefig.facecolor":"black",
            "axes.edgecolor":   "white",
            "axes.labelcolor":  "white",
            "xtick.color":      "white",
            "ytick.color":      "white",
        }):
            names = list(samples_for_plots.keys())
            R, C = len(Ks), 1 + len(names)
            fig, axs = plt.subplots(R, C, figsize=(4.3*C, 3.1*R), sharex=True, sharey=True)
            if R == 1 and C == 1: axs = np.array([[axs]])
            elif R == 1: axs = np.array([axs])
            elif C == 1: axs = np.array([[ax] for ax in axs])

            for r, K in enumerate(Ks):
                panels = [("target", Ht)]
                flats  = [Ht.ravel()]
                for name in names:
                    Xm2 = samples_for_plots[name][K]
                    Hm, *_ = np.histogram2d(Xm2[:,0], Xm2[:,1], bins=[y_edges, z_edges], density=True)
                    panels.append((f"{name}", Hm))
                    flats.append(Hm.ravel())
                vmax = np.percentile(np.concatenate(flats), hist_vmax_percentile)
                norm = PowerNorm(gamma=max(1e-3, float(hist_gamma)), vmin=0.0, vmax=max(1e-9, vmax))
                for c, (title, H) in enumerate(panels):
                    ax = axs[r, c] if R > 1 else axs[0, c]
                    ax.imshow(H.T, origin="lower", extent=[xlim[0], xlim[1], ylim[0], ylim[1]],
                              cmap=hist_cmap, norm=norm, interpolation="bilinear", alpha=1.0, aspect="equal")
                    if c == 0: ax.set_title("target", color='w', pad=3)
                    else:      ax.set_title(f"K={K} — {title}", color='w', pad=3)
                    if r == R-1: ax.set_xlabel("proj x", color='w')
                    if c == 0:   ax.set_ylabel("proj y", color='w')
                    ax.tick_params(color='w', labelcolor='w')

            fig.suptitle("Projected histograms by sampler (target in left column)", y=0.995, color='w')
            fig.tight_layout()
            if hist_out_dir is not None:
                os.makedirs(hist_out_dir, exist_ok=True)
                saved_path = os.path.join(hist_out_dir, f"{hist_prefix}_hists_{R}x{C}.png")
                fig.savefig(saved_path, dpi=170, bbox_inches="tight", facecolor='black')
                print(f"[heat grid saved] {saved_path}")
            plt.show()

    print("[bench] completed benchmark_samplers_proj.")
    return results


# --------------------------------- Chords helpers -------------------------------------
@torch.no_grad()
def chords_pairs_nd(model: AVRC, n=4096, mode="encoder"):
    x1 = sample_target_torch(n)
    if mode == "encoder":
        mu0, _, _ = unpack_encoder_output(model.Enc(x1))
        x_ref = mu0
    elif mode == "gauss":
        x_ref = torch.randn(n, 2, device=device, dtype=TDTYPE)
    else:
        raise ValueError("mode must be 'encoder' or 'gauss'")
    return x_ref, x1


import os, sys, shutil, contextlib
from pathlib import Path


def _safe_rmtree(path: str | Path):
    try:
        shutil.rmtree(path, ignore_errors=True)
    except Exception:
        pass

def _safe_remove(path: str | Path):
    p = Path(path)
    try:
        if p.is_dir():
            shutil.rmtree(p, ignore_errors=True)
        elif p.exists():  # file, symlink, etc.
            p.unlink(missing_ok=True)
    except Exception:
        pass

def _wipe_work_dirs():
    for d in [
        "viz_crossings3d",
        "viz_rf_snapshots",
        "rf_snapshots",
        "bench_hists_nd",
        "training_plots",
        "training_plots.zip",   # <- in case a previous zip is in the way
        "viz"
    ]:
        _safe_remove(d)


def main1(target="checker", embedding="identity", K=2):
    """
    Train in ambient dimension K by embedding the intrinsic 2-D target using `embedding`.
    Valid embeddings: {"identity","linear","sine_wiggle","rff","radial"}.
    """
    set_target(target)
    set_embedding(embedding, K)


    fit_target_whitener(
        num=200_000,
        embedding_mode=embedding,
        k_dim=K,
    )

    rounds = 100

    avrc = AVRC(
        AVRCConfig(
            D=K,
            rounds=rounds,
            batch=4096,
            log_every=1,
            k_plot=5,
            test_rf_every = 5,
            viz_camera=(10, -40),
            organizer_recon_weight=1.0,
            organizer_align_weight=0.0,
            organizer_kl_weight=.4,
            critic_recon_weight=1.0,
            critic_align_weight=0.0,
            viz_latent=True,
            viz_proj_mode="pca",
            viz_num_projections=2,
            viz_proj_source="target",
        )
    )
    avrc.train(progress=True, seed=0)


    rf_model, rf_sampler = train_rectified_flow_nd(
        D=K,
        steps=avrc.cfg.test_rf_steps,
        batch=avrc.cfg.test_rf_batch,
        lr=avrc.cfg.test_rf_lr,
        clip=avrc.cfg.test_rf_clip,
        log_every=avrc.cfg.test_rf_log_every,
        hidden=avrc.cfg.test_rf_hidden,
        depth=avrc.cfg.test_rf_depth,
        weight_decay=0.0,
        seed=avrc.cfg.test_rf_seed,
    )

    avrc_oracle = avrc_oracle_sampler_torch_nd(avrc)

    # choose one cached projection for quick single-view plots
    P = avrc._viz_proj_pairs[0] if avrc._viz_proj_pairs else choose_projection_pairs(K, num_pairs=1)[0]

    samplers = {
        "AVRC (q(z) init)": avrc_oracle,
        "AVRC (N→* joint)": avrc,
        "Rectified Flow":   rf_sampler,
    }
    if getattr(avrc, "posthoc_rf_sampler", None) is not None:
        samplers["AVRC post-hoc RF"] = avrc.posthoc_rf_sampler
    benchmark_samplers_proj(samplers, P=P, Ks=(2, 4, 8), n=100_000)
    plot_output_heatmaps_proj(avrc,        P=P, n=150_000, nfe=1, title=f"AVRC (N→*) on '{TARGET}' [{embedding}, K={K}]")
    plot_output_heatmaps_proj(avrc_oracle, P=P, n=150_000, nfe=1, title=f"AVRC (q(z) init) on '{TARGET}' [{embedding}, K={K}]")
    plot_output_heatmaps_proj(rf_sampler,  P=P, n=150_000, nfe=8, title=f"Rectified Flow on '{TARGET}' [{embedding}, K={K}]")



if __name__ == "__main__":
    _wipe_work_dirs()
    main1(target = 'checker', embedding = 'identity', K = 2)

!ffmpeg -y -framerate 3 -pattern_type glob -i 'viz/hists/hists_*.png' \
  -vf "scale=trunc(iw/2)*2:trunc(ih/2)*2" \
  -c:v libx264 -pix_fmt yuv420p viz/hists_movie.mp4

# 1) movie from rf_probe_*.png
!ffmpeg -y -framerate 3 -pattern_type glob -i 'rf_snapshots/v_probe_*_p00.png' \
  -vf "scale=trunc(iw/2)*2:trunc(ih/2)*2" \
  -c:v libx264 -pix_fmt yuv420p rf_snapshots/rf_probe.mp4

# 2) movie from rf_probe_*_latent.png
!ffmpeg -y -framerate 3 -pattern_type glob -i 'rf_snapshots/v_probe_*_p00_latent.png' \
  -vf "scale=trunc(iw/2)*2:trunc(ih/2)*2" \
  -c:v libx264 -pix_fmt yuv420p rf_snapshots/rf_probe_latent.mp4

# 1) viz_crossings3d/cross_*.png  ---> cross.mp4
!ffmpeg -y -framerate 3 -pattern_type glob -i 'viz_crossings3d/cross_*_p00.png' \
  -vf "scale=trunc(iw/2)*2:trunc(ih/2)*2" \
  -c:v libx264 -pix_fmt yuv420p viz_crossings3d/cross.mp4

# 2) viz_crossings3d/latent_*.png ---> latent.mp4
!ffmpeg -y -framerate 3 -pattern_type glob -i 'viz_crossings3d/latent_*_p00.png' \
  -vf "scale=trunc(iw/2)*2:trunc(ih/2)*2" \
  -c:v libx264 -pix_fmt yuv420p viz_crossings3d/latent.mp4

# 3) viz_crossings3d/latent_mu_*.png ---> latent_mu.mp4
!ffmpeg -y -framerate 3 -pattern_type glob -i 'viz_crossings3d/latent_mu_*_p00.png' \
  -vf "scale=trunc(iw/2)*2:trunc(ih/2)*2" \
  -c:v libx264 -pix_fmt yuv420p viz_crossings3d/latent_mu.mp4
